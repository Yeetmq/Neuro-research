{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ibm.com/think/topics/transformer-model\n",
    "# https://blogs.nvidia.com/blog/what-is-a-transformer-model/\n",
    "\n",
    "import trafilatura\n",
    "html = trafilatura.fetch_url(\"https://www.ibm.com/think/topics/transformer-model\")\n",
    "text = trafilatura.extract(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 0 ссылок. Результаты сохранены в results.txt\n"
     ]
    }
   ],
   "source": [
    "def google_parser(search_query, output_file=\"results.txt\", num_results=10, delay=5):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Referer\": \"https://www.google.com/\",\n",
    "    }\n",
    "\n",
    "    collected_links = []\n",
    "    try:\n",
    "        url = f\"https://www.google.com/search?q={urllib.parse.quote_plus(search_query)}&num={num_results}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(\"Status Code:\", response.status_code)  # Отладка\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Попробуйте разные селекторы:\n",
    "        for a in soup.select('div.tF2Cxc a, div.yuRUbf a, div.g a'):\n",
    "            link = a['href']\n",
    "            if link.startswith(\"/url?\"):\n",
    "                link = urllib.parse.parse_qs(urllib.parse.urlparse(link).query)['q'][0]\n",
    "            collected_links.append(link)\n",
    "\n",
    "        # Сохранение в файл\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(collected_links[:num_results]))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The transformer model is a type of neural network architecture that excels at processing sequential data, most prominently associated with large language models (LLMs). Transformer models have also achieved elite performance in other fields of artificial intelligence (AI), such as computer vision, speech recognition and time series forecasting.\\nThe transformer architecture was first described in the seminal 2017 paper \"Attention is All You Need\" by Vaswani and others, which is now considered a watershed moment in deep learning.\\nOriginally introduced as an evolution of the recurrent neural network (RNN)-based sequence-to-sequence models used for machine translation, transformer-based models have since attained cutting-edge advancements across nearly every machine learning (ML) discipline.\\nDespite their versatility, transformer models are still most commonly discussed in the context of natural language processing (NLP) use cases, such as chatbots, text generation, summarization, question answering and sentiment analysis.\\nThe BERT (or Bidirectional Encoder Representations from Transformers) encoder-decoder model, introduced by Google in 2019, was a major landmark in the establishment of transformers and remains the basis of most modern word embedding applications, from modern vector databases to Google search.\\nAutoregressive decoder-only LLMs, such as the GPT-3 (short for Generative Pre-trained Transformer) model that powered the launch of OpenAI’s ChatGPT, catalyzed the modern era of generative AI (gen AI).\\nThe ability of transformer models to intricately discern how each part of a data sequence influences and correlates with the others also lends them many multimodal uses.\\nFor instance, vision transformers (ViTs) often exceed the performance of convolutional neural networks (CNNs) on image segmentation, object detection and related tasks. The transformer architecture also powers many diffusion models used for image generation, multimodal text-to-speech (TTS) and vision language models (VLMs).\\nThe central feature of transformer models is their self-attention mechanism, from which transformer models derive their impressive ability to detect the relationships (or dependencies) between each part of an input sequence. Unlike the RNN and CNN architectures that preceded it, the transformer architecture uses only attention layers and standard feedforward layers.\\nThe benefits of self-attention, and specifically the multi-head attention technique that transformer models employ to compute it, are what enable transformers to exceed the performance of the RNNs and CNNs that had previously been state-of-the-art.\\nBefore the introduction of transformer models, most NLP tasks relied on recurrent neural networks (RNNs). The way RNNs process sequential data is inherently serialized: they ingest the elements of an input sequence one at a time and in a specific order.\\nThis hinders the ability of RNNs to capture long-range dependencies, meaning RNNs can only process short text sequences effectively.\\nThis deficiency was somewhat addressed by the introduction of long short term memory networks (LSTMs), but remains a fundamental shortcoming of RNNs.\\nAttention mechanisms, conversely, can examine an entire sequence simultaneously and make decisions about how and when to focus on specific time steps of that sequence.\\nIn addition to significantly improving the ability to understand long-range dependencies, this quality of transformers also allows for parallelization: the ability to perform many computational steps at once, rather than in a serialized manner.\\nBeing well-suited to parallelism enables transformer models to take full advantage of the power and speed offered by GPUs during both training and inference. This possibility, in turn, unlocked the opportunity to train transformer models on unprecedentedly massive datasets through self-supervised learning.\\nEspecially for visual data, transformers also offer some advantages over convolutional neural networks. CNNs are inherently local, using convolutions to process smaller subsets of input data one piece at a time.\\nTherefore, CNNs also struggle to discern long-range dependencies, such as correlations between words (in text) or pixels (in images) that aren’t neighboring one another. Attention mechanisms don’t have this limitation.\\nUnderstanding the mathematical concept of attention, and more specifically self-attention, is essential to understanding the success of transformer models in so many fields. Attention mechanisms are, in essence, algorithms designed to determine which parts of a data sequence an AI model should “pay attention to” at any particular moment.\\nConsider a language model interpreting the English text \"\\nBroadly speaking, a transformer model’s attention layers assess and use the specific context of each part of a data sequence in 4 steps:\\nBefore training, a transformer model doesn’t yet “know” how to generate optimal vector embeddings and alignment scores. During training, the model makes predictions across millions of examples drawn from its training data, and a loss function quantifies the error of each prediction.\\nThrough an iterative cycle of making predictions and then updating model weights through backpropagation and gradient descent, the model “learns” to generate vector embeddings, alignment scores and attention weights that lead to accurate outputs.\\nTransformer models such as relational databases generate query, key and value vectors for each part of a data sequence, and use them to compute attention weights through a series of matrix multiplications.\\nRelational databases are designed to simplify the storage and retrieval of relevant data: they assign a unique identifier (“key”) to each piece of data, and each key is associated with a corresponding value. The “Attention is All You Need” paper applied that conceptual framework to processing the relationships between each token in a sequence of text.\\nFor an LLM, the model’s “database” is the vocabulary of tokens it has learned from the text samples in its training data. Its attention mechanism uses information from this “database” to understand the context of language.\\nWhereas characters—letters, numbers or punctuation marks—are the base unit we humans use to represent language, the smallest unit of language that AI models use is a token. Each token is assigned an ID number, and these ID numbers (rather than the words or even the tokens themselves) are the way LLMs navigate their vocabulary “database.” This tokenization of language significantly reduces the computational power needed to process text.\\nTo generate query and key vectors to feed into the transformer’s attention layers, the model needs an initial, contextless vector embedding for each token. These initial token embeddings can be either learned during training or taken from a pretrained word embedding model.\\nThe order and position of words can significantly impact their semantic meanings. Whereas the serialized nature of RNNs inherently preserves information about the position of each token, transformer models must explicitly add positional information for the attention mechanism to consider.\\nWith positional encoding, the model adds a vector of values to each token’s embedding, derived from its relative position, before the input enters the attention mechanism. The nearer the 2 tokens are, the more similar their positional vectors will be and therefore, the more their alignment score will increase from adding positional information. The model thereby learns to pay greater attention to nearby tokens.\\nWhen positional information has been added, each updated token embedding is used to generate three new vectors. These query, key and value vectors are generated by passing the original token embeddings through each of three parallel feedforward neural network layers that precede the first attention layer. Each parallel subset of that linear layer has a unique matrix of weights, learned through self-supervised pretraining on a massive dataset of text.\\nThe transformer’s attention mechanism’s primary function is to assign accurate attention weights to the pairings of each token’s query vector with the key vectors of all the other tokens in the sequence. When achieved, you can think of each token as now having a corresponding vector of attention weights, in which each element of that vector represents the extent to which some other token should influence it.\\nIn essence, \\'s vector embedding has been updated to better reflect the context provided by the other tokens in the sequence.\\nTo capture the many multifaceted ways tokens might relate to one another, transformer models implement multi-head attention across multiple attention blocks.\\nBefore being fed into the first feedforward layer, each original input token embedding is split into h evenly sized subsets. Each piece of the embedding is fed into one of h parallel matrices of Q, K and V weights, each of which are called a query head, key head or value head. The vectors output by each of these parallel triplets of query, key and value heads are then fed into a corresponding subset of the next attention layer, called an attention head.\\nIn the final layers of each attention block, the outputs of these h parallel circuits are eventually concatenated back together before being sent to the next feedforward layer. In practice, model training results in each circuit learning different weights that capture a separate aspect of semantic meanings.\\nIn some situations, passing along the contextually-updated embedding output by the attention block might result in an unacceptable loss of information from the original sequence.\\nTo address this, transformer models often balance the contextual information provided by the attention mechanism with the original semantic meaning of each token. After the attention-updated subsets of the token embedding have all been concatenated back together, the updated vector is then added to the token’s original (position-encoded) vector embedding. The original token embedding is supplied by a residual connection between that layer and an earlier layer of the network.\\nThe resulting vector is fed into another linear feedforward layer, where it’s normalized back to a constant size before being passed along to the next attention block. Together, these measures help preserve stability in training and help ensure that the text’s original meaning is not lost as the data moves deeper into the neural network.\\nEventually, the model has enough contextual information to inform its final outputs. The nature and function of the output layer will depend on the specific task the transformer model has been designed for.\\nIn autoregressive LLMs, the final layer uses a softmax function to determine the probability that the next word will match each token in its vocabulary “database.” Depending on the specific sampling hyperparameters, the model uses those probabilities to determine the next token of the output sequence.\\nTransformer models are most commonly associated with NLP, having originally been developed for machine translation use cases. Most notably, the transformer architecture gave rise to the large language models (LLMs) that catalyzed the advent of generative AI.\\nMost of the LLMs that the public is most familiar with, from closed source models such as OpenAI’s GPT series and Anthropic’s Claude models to open source models including Meta Llama or IBM® Granite®, are autoregressive decoder-only LLMs.\\nAutoregressive LLMs are designed for text generation, which also extends naturally to adjacent tasks such as summarization and question answering. They’re trained through self-supervised learning, in which the model is provided the first word of a text passage and tasked with iteratively predicting the next word until the end of the sequence.\\nInformation provided by the self-attention mechanism enables the model to extract context from the input sequence and maintain the coherence and continuity of its output.\\nEncoder-decoder masked language models (MLMs), such as BERT and its many derivatives, represent the other main evolutionary branch of transformer-based LLMs. In training, an MLM is provided a text sample with some tokens masked—hidden—and tasked with completing the missing information.\\nWhile this training methodology is less effective for text generation, it helps MLMs excel at tasks requiring robust contextual information, such as translation, text classification and learning embeddings.\\nThough transformer models were originally designed for, and continue to be most prominently associated with natural language use cases, they can be used in nearly any situation involving sequential data. This has led to the development of transformer-based models in other fields, from fine-tuning LLMs into multimodal systems to dedicated time series forecasting models and ViTs for computer vision.\\nSome data modalities are more naturally suited to transformer-friendly sequential representation than others. Time series, audio and video data are inherently sequential, whereas image data is not. Despite this, ViTs and other attention-based models have achieved state-of-the-art results for many computer vision tasks, including image captioning, object detection, image segmentation and visual question answering.\\nTo use transformer models for data not conventionally thought of as \"sequential\" requires a conceptual workaround to represent that data as a sequence. For instance, to use attention mechanisms to understand visual data, ViTs use patch embeddings to make image data interpretable as sequences.\\nTrain, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data.\\nPut AI to work in your business with IBM\\'s industry-leading AI expertise and portfolio of solutions at your side.\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n1 Google’s BERT Rolls Out Worldwide (link resides outside ibm.com), Search Engine Journal, Dec 9, 2019'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 links. Saved to results.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "def google_parser(search_query, output_file=\"results.txt\", num_results=10, delay=5):\n",
    "    \"\"\"\n",
    "    Парсит английские результаты Google с обновленными селекторами\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    "\n",
    "    collected_links = []\n",
    "    \n",
    "    try:\n",
    "        # Кодируем запрос для URL\n",
    "        encoded_query = urllib.parse.quote_plus(search_query)\n",
    "        url = f\"https://www.google.com/search?q={encoded_query}&num={num_results}&gl=us&hl=en\"\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        # Проверка на капчу\n",
    "        if \"CAPTCHA\" in response.text or \"demanded\" in response.text:\n",
    "            print(\"Google требует CAPTCHA! Используйте прокси или ручной вход.\")\n",
    "            return\n",
    "\n",
    "        # Сохраняем сырой HTML для отладки\n",
    "        with open(\"google_dump.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Актуальные селекторы на июль 2024\n",
    "        for result in soup.select('div.g, div.tF2Cxc, div.yuRUbf'):\n",
    "            link = result.find('a', href=True)\n",
    "            if link:\n",
    "                href = link['href']\n",
    "                # Обрабатываем Google-редиректы\n",
    "                if href.startswith('/url?'):\n",
    "                    params = urllib.parse.parse_qs(urllib.parse.urlparse(href).query)\n",
    "                    href = params.get('q', [href])[0]\n",
    "                collected_links.append(href)\n",
    "\n",
    "        # Сохраняем результаты\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(collected_links[:num_results]))\n",
    "\n",
    "        print(f\"Found {len(collected_links)} links. Saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Пример использования (английский запрос)\n",
    "google_parser(\"machine learning transformers research papers\", num_results=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object MySpider.parse at 0x0000014EDEFF3040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'link_spider'\n",
    "    start_urls = ['https://www.google.com']  # Укажите стартовый URL\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Инициализируем LinkExtractor с фильтрами\n",
    "        link_extractor = LinkExtractor(\n",
    "            allow_domains=[urlparse(response.url).hostname],  # Только текущий домен\n",
    "            deny=[],  # При необходимости добавьте исключения\n",
    "            canonicalize=True\n",
    "        )\n",
    "\n",
    "        # Собираем данные\n",
    "        data = {\n",
    "            'url': [],\n",
    "            'link_text': [],\n",
    "            'source_page': []\n",
    "        }\n",
    "\n",
    "        # Извлекаем все ссылки с их текстом\n",
    "        for link in link_extractor.extract_links(response):\n",
    "            data['url'].append(link.url)\n",
    "            data['link_text'].append(link.text.strip())\n",
    "            data['source_page'].append(response.url)\n",
    "\n",
    "        # Дополнительно: парсим текст со страницы\n",
    "        text_content = ' '.join(response.xpath('//body//text()').getall()).strip()\n",
    "        text_content = ' '.join(text_content.split())  # Удаляем лишние пробелы\n",
    "\n",
    "        # Для экспорта в DataFrame (но лучше использовать Scrapy Items)\n",
    "        yield {\n",
    "            'page_url': response.url,\n",
    "            'page_content': text_content,\n",
    "            'links': data\n",
    "        }\n",
    "\n",
    "        # Рекурсивный переход по ссылкам (опционально)\n",
    "        for link in link_extractor.extract_links(response):\n",
    "            yield response.follow(link.url, callback=self.parse)\n",
    "\n",
    "\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "\n",
    "process = CrawlerProcess(settings={\n",
    "    'FEED_FORMAT': 'json',\n",
    "    'FEED_URI': 'output.json'\n",
    "})\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium_stealth import stealth\n",
    "import time\n",
    "\n",
    "def google_selenium(query, num=10):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # Маскируем Selenium\n",
    "    stealth(driver,\n",
    "        languages=[\"en-US\", \"en\"],\n",
    "        vendor=\"Google Inc.\",\n",
    "        platform=\"Win32\",\n",
    "        webgl_vendor=\"Intel Inc.\",\n",
    "        renderer=\"Intel Iris OpenGL Engine\",\n",
    "        fix_hairline=True\n",
    "    )\n",
    "    \n",
    "    driver.get(f\"https://www.google.com/search?q={query}&num={num}\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Извлекаем ссылки\n",
    "    links = [a.get_attribute('href') for a in driver.find_elements(\"css selector\", \"a\")]\n",
    "    driver.quit()\n",
    "    \n",
    "    # Фильтруем результаты\n",
    "    return [link for link in links if 'url?q=' in link][:num]\n",
    "\n",
    "# Пример использования\n",
    "print(google_selenium(\"Transformers in machine learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yandex_results(query):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  \n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")  \n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    chrome_options.add_argument(\"--lang=ru-RU\")\n",
    "    \n",
    "    driver_path = r\"D:\\ethd\\ml\\chromedriver-win64\\chromedriver.exe\"\n",
    "\n",
    "    service = Service(driver_path)\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://yandex.ru/search/?text={query.replace(' ', '+')}\"\n",
    "        driver.get(url)\n",
    "        \n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-cid]\"))\n",
    "        )\n",
    "        \n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        for _ in range(3):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(1.5)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        \n",
    "        links = []\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \"li.serp-item a.Link_theme_outer\")\n",
    "        \n",
    "        excluded_keywords = {\"course\", \"edu\", \"lesson\", \"school\", 'курс', \"урок\"}\n",
    "        \n",
    "        for link in results:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href and not href.startswith(\"https://yandex.ru\"):\n",
    "                if href and not any(keyword in href.lower() for keyword in excluded_keywords) and href not in links:\n",
    "                    links.append(href)\n",
    "                \n",
    "        return list(set(links))[:20]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        driver.quit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ibm.com/think/topics/transformer-model\n",
    "# https://blogs.nvidia.com/blog/what-is-a-transformer-model/\n",
    "\n",
    "import trafilatura\n",
    "html = trafilatura.fetch_url(\"https://www.ibm.com/think/topics/transformer-model\")\n",
    "text = trafilatura.extract(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "def get_google_results(query, num_results):\n",
    "\n",
    "    results = list(\n",
    "        search(\n",
    "            query, \n",
    "            num_results=num_results,\n",
    "            lang=\"en\",\n",
    "            advanced=False\n",
    "            ))\n",
    "    return results\n",
    "\n",
    "links = get_google_results('Transformers in machine learning', num_results=10)\n",
    "\n",
    "result_path = r'D:\\ethd\\ml\\Neuro-research\\utils\\test_links.txt'\n",
    "with open(result_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    for link in links:\n",
    "        file.write(link + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)': /inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "ERROR:trafilatura.core:empty HTML tree: None\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)': /tutorial/how-transformers-work\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: medium.com. Connection pool size: 1\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)': /inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)': /what-is/transformers-in-artificial-intelligence/\n",
      "ERROR:trafilatura.downloads:download error: https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04 HTTPSConnectionPool(host='medium.com', port=443): Max retries exceeded with url: /inside-machine-learning/what-is-a-transformer-d07dd1fbec04 (Caused by ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)))\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: www.datacamp.com. Connection pool size: 1\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)': /tutorial/how-transformers-work\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: aws.amazon.com. Connection pool size: 1\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)': /what-is/transformers-in-artificial-intelligence/\n",
      "ERROR:trafilatura.downloads:download error: https://www.datacamp.com/tutorial/how-transformers-work HTTPSConnectionPool(host='www.datacamp.com', port=443): Max retries exceeded with url: /tutorial/how-transformers-work (Caused by ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)))\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "ERROR:trafilatura.downloads:download error: https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/ HTTPSConnectionPool(host='aws.amazon.com', port=443): Max retries exceeded with url: /what-is/transformers-in-artificial-intelligence/ (Caused by ProtocolError('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None)))\n",
      "WARNING:trafilatura.core:discarding data: None\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "def get_page_content(link, timeout=5):\n",
    "    result = None\n",
    "    def task():\n",
    "        nonlocal result\n",
    "        try:\n",
    "            html = trafilatura.fetch_url(link)\n",
    "            result = trafilatura.extract(html)\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "    thread = Thread(target=task)\n",
    "    thread.start()\n",
    "    thread.join(timeout)\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    links = []\n",
    "    result_path = r'D:\\ethd\\ml\\Neuro-research\\utils\\test_links.txt'\n",
    "    \n",
    "    # Читаем ссылки\n",
    "    with open(result_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line:\n",
    "                links.append(stripped_line)\n",
    "\n",
    "    # Сохраняем результаты\n",
    "    result_path = r'D:\\ethd\\ml\\Neuro-research\\utils\\test_content.txt'\n",
    "    with open(result_path, \"a\", encoding=\"utf-8\") as file:\n",
    "        for link in links:\n",
    "            content = get_page_content(link)\n",
    "            # Добавляем проверку на None\n",
    "            file.write('-'*80)\n",
    "            file.write('\\n')\n",
    "            file.write(link)\n",
    "            file.write('\\n')\n",
    "            file.write('-'*80)\n",
    "            file.write(f\"{content or ''}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trafilatura\n",
    "import multiprocessing\n",
    "from queue import Empty\n",
    "\n",
    "# Выносим worker в глобальную область видимости\n",
    "def worker(link, queue):\n",
    "    try:\n",
    "        html = trafilatura.fetch_url(link)\n",
    "        text = trafilatura.extract(html)\n",
    "        queue.put(text or None)\n",
    "    except Exception:\n",
    "        queue.put(None)\n",
    "\n",
    "def get_page_content(link, timeout=10):\n",
    "    queue = multiprocessing.Queue()\n",
    "    process = multiprocessing.Process(target=worker, args=(link, queue))\n",
    "    process.start()\n",
    "    process.join(timeout=timeout)\n",
    "\n",
    "    if process.is_alive():\n",
    "        process.terminate()\n",
    "        process.join()\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            return queue.get_nowait()\n",
    "        except Empty:\n",
    "            return None\n",
    "\n",
    "# Добавляем защиту точки входа\n",
    "if __name__ == '__main__':\n",
    "    links = []\n",
    "    result_path = r'D:\\ethd\\ml\\Neuro-research\\utils\\test_links.txt'\n",
    "    \n",
    "    # Читаем ссылки\n",
    "    with open(result_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line:\n",
    "                links.append(stripped_line)\n",
    "\n",
    "    # Сохраняем результаты\n",
    "    result_path = r'D:\\ethd\\ml\\Neuro-research\\utils\\test_content.txt'\n",
    "    with open(result_path, \"a\", encoding=\"utf-8\") as file:\n",
    "        for link in links:\n",
    "            content = get_page_content(link)\n",
    "            # Добавляем проверку на None\n",
    "            file.write(f\"{content or ''}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The transformer model is a type of neural network architecture that excels at processing sequential data, most prominently associated with large language models (LLMs). Transformer models have also achieved elite performance in other fields of artificial intelligence (AI), such as computer vision, speech recognition and time series forecasting.\\nThe transformer architecture was first described in the seminal 2017 paper \"Attention is All You Need\" by Vaswani and others, which is now considered a watershed moment in deep learning.\\nOriginally introduced as an evolution of the recurrent neural network (RNN)-based sequence-to-sequence models used for machine translation, transformer-based models have since attained cutting-edge advancements across nearly every machine learning (ML) discipline.\\nDespite their versatility, transformer models are still most commonly discussed in the context of natural language processing (NLP) use cases, such as chatbots, text generation, summarization, question answering and sentiment analysis.\\nThe BERT (or Bidirectional Encoder Representations from Transformers) encoder-decoder model, introduced by Google in 2019, was a major landmark in the establishment of transformers and remains the basis of most modern word embedding applications, from modern vector databases to Google search.\\nAutoregressive decoder-only LLMs, such as the GPT-3 (short for Generative Pre-trained Transformer) model that powered the launch of OpenAI’s ChatGPT, catalyzed the modern era of generative AI (gen AI).\\nThe ability of transformer models to intricately discern how each part of a data sequence influences and correlates with the others also lends them many multimodal uses.\\nFor instance, vision transformers (ViTs) often exceed the performance of convolutional neural networks (CNNs) on image segmentation, object detection and related tasks. The transformer architecture also powers many diffusion models used for image generation, multimodal text-to-speech (TTS) and vision language models (VLMs).\\nThe central feature of transformer models is their self-attention mechanism, from which transformer models derive their impressive ability to detect the relationships (or dependencies) between each part of an input sequence. Unlike the RNN and CNN architectures that preceded it, the transformer architecture uses only attention layers and standard feedforward layers.\\nThe benefits of self-attention, and specifically the multi-head attention technique that transformer models employ to compute it, are what enable transformers to exceed the performance of the RNNs and CNNs that had previously been state-of-the-art.\\nBefore the introduction of transformer models, most NLP tasks relied on recurrent neural networks (RNNs). The way RNNs process sequential data is inherently serialized: they ingest the elements of an input sequence one at a time and in a specific order.\\nThis hinders the ability of RNNs to capture long-range dependencies, meaning RNNs can only process short text sequences effectively.\\nThis deficiency was somewhat addressed by the introduction of long short term memory networks (LSTMs), but remains a fundamental shortcoming of RNNs.\\nAttention mechanisms, conversely, can examine an entire sequence simultaneously and make decisions about how and when to focus on specific time steps of that sequence.\\nIn addition to significantly improving the ability to understand long-range dependencies, this quality of transformers also allows for parallelization: the ability to perform many computational steps at once, rather than in a serialized manner.\\nBeing well-suited to parallelism enables transformer models to take full advantage of the power and speed offered by GPUs during both training and inference. This possibility, in turn, unlocked the opportunity to train transformer models on unprecedentedly massive datasets through self-supervised learning.\\nEspecially for visual data, transformers also offer some advantages over convolutional neural networks. CNNs are inherently local, using convolutions to process smaller subsets of input data one piece at a time.\\nTherefore, CNNs also struggle to discern long-range dependencies, such as correlations between words (in text) or pixels (in images) that aren’t neighboring one another. Attention mechanisms don’t have this limitation.\\nUnderstanding the mathematical concept of attention, and more specifically self-attention, is essential to understanding the success of transformer models in so many fields. Attention mechanisms are, in essence, algorithms designed to determine which parts of a data sequence an AI model should “pay attention to” at any particular moment.\\nConsider a language model interpreting the English text \"\\nBroadly speaking, a transformer model’s attention layers assess and use the specific context of each part of a data sequence in 4 steps:\\nBefore training, a transformer model doesn’t yet “know” how to generate optimal vector embeddings and alignment scores. During training, the model makes predictions across millions of examples drawn from its training data, and a loss function quantifies the error of each prediction.\\nThrough an iterative cycle of making predictions and then updating model weights through backpropagation and gradient descent, the model “learns” to generate vector embeddings, alignment scores and attention weights that lead to accurate outputs.\\nTransformer models such as relational databases generate query, key and value vectors for each part of a data sequence, and use them to compute attention weights through a series of matrix multiplications.\\nRelational databases are designed to simplify the storage and retrieval of relevant data: they assign a unique identifier (“key”) to each piece of data, and each key is associated with a corresponding value. The “Attention is All You Need” paper applied that conceptual framework to processing the relationships between each token in a sequence of text.\\nFor an LLM, the model’s “database” is the vocabulary of tokens it has learned from the text samples in its training data. Its attention mechanism uses information from this “database” to understand the context of language.\\nWhereas characters—letters, numbers or punctuation marks—are the base unit we humans use to represent language, the smallest unit of language that AI models use is a token. Each token is assigned an ID number, and these ID numbers (rather than the words or even the tokens themselves) are the way LLMs navigate their vocabulary “database.” This tokenization of language significantly reduces the computational power needed to process text.\\nTo generate query and key vectors to feed into the transformer’s attention layers, the model needs an initial, contextless vector embedding for each token. These initial token embeddings can be either learned during training or taken from a pretrained word embedding model.\\nThe order and position of words can significantly impact their semantic meanings. Whereas the serialized nature of RNNs inherently preserves information about the position of each token, transformer models must explicitly add positional information for the attention mechanism to consider.\\nWith positional encoding, the model adds a vector of values to each token’s embedding, derived from its relative position, before the input enters the attention mechanism. The nearer the 2 tokens are, the more similar their positional vectors will be and therefore, the more their alignment score will increase from adding positional information. The model thereby learns to pay greater attention to nearby tokens.\\nWhen positional information has been added, each updated token embedding is used to generate three new vectors. These query, key and value vectors are generated by passing the original token embeddings through each of three parallel feedforward neural network layers that precede the first attention layer. Each parallel subset of that linear layer has a unique matrix of weights, learned through self-supervised pretraining on a massive dataset of text.\\nThe transformer’s attention mechanism’s primary function is to assign accurate attention weights to the pairings of each token’s query vector with the key vectors of all the other tokens in the sequence. When achieved, you can think of each token as now having a corresponding vector of attention weights, in which each element of that vector represents the extent to which some other token should influence it.\\nIn essence, \\'s vector embedding has been updated to better reflect the context provided by the other tokens in the sequence.\\nTo capture the many multifaceted ways tokens might relate to one another, transformer models implement multi-head attention across multiple attention blocks.\\nBefore being fed into the first feedforward layer, each original input token embedding is split into h evenly sized subsets. Each piece of the embedding is fed into one of h parallel matrices of Q, K and V weights, each of which are called a query head, key head or value head. The vectors output by each of these parallel triplets of query, key and value heads are then fed into a corresponding subset of the next attention layer, called an attention head.\\nIn the final layers of each attention block, the outputs of these h parallel circuits are eventually concatenated back together before being sent to the next feedforward layer. In practice, model training results in each circuit learning different weights that capture a separate aspect of semantic meanings.\\nIn some situations, passing along the contextually-updated embedding output by the attention block might result in an unacceptable loss of information from the original sequence.\\nTo address this, transformer models often balance the contextual information provided by the attention mechanism with the original semantic meaning of each token. After the attention-updated subsets of the token embedding have all been concatenated back together, the updated vector is then added to the token’s original (position-encoded) vector embedding. The original token embedding is supplied by a residual connection between that layer and an earlier layer of the network.\\nThe resulting vector is fed into another linear feedforward layer, where it’s normalized back to a constant size before being passed along to the next attention block. Together, these measures help preserve stability in training and help ensure that the text’s original meaning is not lost as the data moves deeper into the neural network.\\nEventually, the model has enough contextual information to inform its final outputs. The nature and function of the output layer will depend on the specific task the transformer model has been designed for.\\nIn autoregressive LLMs, the final layer uses a softmax function to determine the probability that the next word will match each token in its vocabulary “database.” Depending on the specific sampling hyperparameters, the model uses those probabilities to determine the next token of the output sequence.\\nTransformer models are most commonly associated with NLP, having originally been developed for machine translation use cases. Most notably, the transformer architecture gave rise to the large language models (LLMs) that catalyzed the advent of generative AI.\\nMost of the LLMs that the public is most familiar with, from closed source models such as OpenAI’s GPT series and Anthropic’s Claude models to open source models including Meta Llama or IBM® Granite®, are autoregressive decoder-only LLMs.\\nAutoregressive LLMs are designed for text generation, which also extends naturally to adjacent tasks such as summarization and question answering. They’re trained through self-supervised learning, in which the model is provided the first word of a text passage and tasked with iteratively predicting the next word until the end of the sequence.\\nInformation provided by the self-attention mechanism enables the model to extract context from the input sequence and maintain the coherence and continuity of its output.\\nEncoder-decoder masked language models (MLMs), such as BERT and its many derivatives, represent the other main evolutionary branch of transformer-based LLMs. In training, an MLM is provided a text sample with some tokens masked—hidden—and tasked with completing the missing information.\\nWhile this training methodology is less effective for text generation, it helps MLMs excel at tasks requiring robust contextual information, such as translation, text classification and learning embeddings.\\nThough transformer models were originally designed for, and continue to be most prominently associated with natural language use cases, they can be used in nearly any situation involving sequential data. This has led to the development of transformer-based models in other fields, from fine-tuning LLMs into multimodal systems to dedicated time series forecasting models and ViTs for computer vision.\\nSome data modalities are more naturally suited to transformer-friendly sequential representation than others. Time series, audio and video data are inherently sequential, whereas image data is not. Despite this, ViTs and other attention-based models have achieved state-of-the-art results for many computer vision tasks, including image captioning, object detection, image segmentation and visual question answering.\\nTo use transformer models for data not conventionally thought of as \"sequential\" requires a conceptual workaround to represent that data as a sequence. For instance, to use attention mechanisms to understand visual data, ViTs use patch embeddings to make image data interpretable as sequences.\\nTrain, validate, tune and deploy generative AI, foundation models and machine learning capabilities with IBM watsonx.ai, a next-generation enterprise studio for AI builders. Build AI applications in a fraction of the time with a fraction of the data.\\nPut AI to work in your business with IBM\\'s industry-leading AI expertise and portfolio of solutions at your side.\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n1 Google’s BERT Rolls Out Worldwide (link resides outside ibm.com), Search Engine Journal, Dec 9, 2019'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_page_content('https://www.ibm.com/think/topics/transformer-model')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено ссылок: 10\n",
      "https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n",
      "https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04\n",
      "https://blogs.nvidia.com/blog/what-is-a-transformer-model/\n",
      "https://www.ibm.com/think/topics/transformer-model\n",
      "https://www.datacamp.com/tutorial/how-transformers-work\n",
      "https://www.reddit.com/r/explainlikeimfive/comments/16y59y3/eli5_what_are_transformers_in_ml/\n",
      "https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/\n",
      "https://www.geeksforgeeks.org/getting-started-with-transformers/\n",
      "https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
      "https://www.youtube.com/watch?v=ZXiruGOCn9s\n"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "query = \"Transformers in machine learning\"\n",
    "num_results = 10\n",
    "\n",
    "results = list(search(\n",
    "    query, \n",
    "    num_results=num_results,\n",
    "    lang=\"en\",\n",
    "    advanced=False\n",
    "))\n",
    "\n",
    "print(\"Найдено ссылок:\", len(results))\n",
    "for url in results:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "\n",
    "process = CrawlerProcess(settings={\n",
    "    'FEED_FORMAT': 'json',\n",
    "    'FEED_URI': 'output.json'\n",
    "})\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer\n",
      "arXiv results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "\n",
      "r\n",
      "a\n",
      "\n",
      "M\n",
      "8\n",
      "2\n",
      "\n",
      "]\n",
      "I\n",
      "\n",
      "N\n",
      ".\n",
      "s\n",
      "c\n",
      "[\n",
      "\n",
      "1\n",
      "v\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      ".\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      ":\n",
      "v\n",
      "i\n",
      "X\n",
      "r\n",
      "a\n",
      "\n",
      "NetSSM: Multi-Flow and State-Aware Network Trace\n",
      "Generation using State-Space Models\n",
      "\n",
      "ANDREW CHU, University of Chicago\n",
      "XI JIANG, University of Chicago\n",
      "SHINAN LIU, University of Chicago\n",
      "ARJUN BHAGOJI, IIT Bombay\n",
      "FRANCESCO BRONZINO, École Normale Supérieure de Lyon\n",
      "PAUL SCHMITT, California Polytechnic State University, San Luis Obispo\n",
      "NICK FEAMSTER, University of Chicago\n",
      "\n",
      "Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to\n",
      "performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules.\n",
      "Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-\n",
      "flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions,\n",
      "and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models\n",
      "called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures\n",
      "interactions between multiple, interleaved flows – an objective unexplored in prior work – and effectively\n",
      "reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning\n",
      "longer than existing transformer-based approaches. Evaluation results\n",
      "from and producing traces 8\n",
      "show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We\n",
      "also find that NetSSM’s traces have high semantic similarity to real network data regarding compliance with\n",
      "standard protocol requirements and flow and session-level traffic characteristics.\n",
      "\n",
      "and 78\n",
      "\n",
      "×\n",
      "\n",
      "×\n",
      "\n",
      "1 INTRODUCTION\n",
      "\n",
      "The demand for representative, scalable network data is constant, driven by critical applications\n",
      "such as security analysis, traffic modeling, and performance evaluation [2, 18, 20, 28, 29, 35, 41, 43].\n",
      "Unfortunately, acquiring large-scale, high-fidelity network data is difficult due to data governance\n",
      "rules, legal restrictions, and the high collection costs [1, 10, 30, 44, 48]. In response, methods have\n",
      "been developed to generate synthetic network data that accurately replicates real networks. These\n",
      "approaches allow researchers and practitioners to test, evaluate, and model network scenarios\n",
      "while minimizing collection overhead and obstacles in accessibility.\n",
      "\n",
      "Existing methods for generating synthetic network data output this data in two forms: (1)\n",
      "sequences of single or multiple derived network traffic attributes, such as flow statistics (e.g., duration,\n",
      "average packet size), packet header fields (e.g., IP flags, addresses), or metadata (e.g., web page views,\n",
      "event types) and (2) raw packet capture (PCAP) traces. Generators producing traffic attributes\n",
      "are comparatively lightweight and can be used to replicate arbitrarily long-duration sessions of\n",
      "networked communication. Generators producing raw packets capture the verbose, inter-, and\n",
      "intra-packet interactions in a flow, and commodity packet analyzers (e.g., Wireshark, tcpdump) can\n",
      "manually analyze their resulting PCAPs.\n",
      "\n",
      "Unfortunately, current methods for either output format have limitations that impact their\n",
      "practical use. Traffic attribute generators cannot reason about the raw contents of stateful protocols,\n",
      "such as TCP, and require retraining to learn the patterns of new targets in a session. Raw packet\n",
      "generators are limited in the length of traces they can train on and produce and, thus, may\n",
      "not capture meaningful communication between nodes beyond initial connection setup. Further,\n",
      "neither generator type can reliably produce data for sessions comprised of more than a single flow,\n",
      "preventing them from being applied to various workloads in the real world, where interleaved,\n",
      "multi-flow communication is common (e.g., distributed systems, IoT). Finally, current methods\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\ffor evaluating the quality of synthetic network data (i.e., statistical similarity to real-world traces\n",
      "and downstream performance of ML models trained on synthetic data) are insufficient. Synthetic\n",
      "data that perform well in, or towards, these evaluations can still fall short in scenarios that require\n",
      "analysis of multi-flow interactions or stateful behaviors in network traffic (e.g., QoE estimation [39],\n",
      "application fingerprinting [25]). Thus, determining the criteria for what qualities or characteristics\n",
      "make synthetic network data “good” is an ongoing area of research.\n",
      "\n",
      "In this paper, we present NetSSM, a raw packet generator for network traffic data built on the\n",
      "recently proposed structured selective state-space model (Mamba) architecture. NetSSM bridges\n",
      "the gap between traffic attribute and raw packet generators by combining the former’s length-\n",
      "scaling capabilities with the latter’s comprehensive packet-level detail. This enables NetSSM to\n",
      "capture a substantially wider range of target events while retaining the ability to capture inter-\n",
      "and intra-packet dependencies across any protocol and layer. Furthermore, the sequential, stateful\n",
      "nature of how NetSSM learns network data allows it to generate sessions comprised of multiple\n",
      "interleaved flows with high fidelity, addressing a critical limitation of existing methods.\n",
      "\n",
      "To evaluate NetSSM, we train model variants on social media, video conferencing, and video\n",
      "streaming traffic. We first assess its performance using established metrics of synthetic network\n",
      "data fidelity (statistical similarity and downstream ML performance). We then evaluate NetSSM\n",
      "through a new lens of semantic similarity to test how well its generated data aligns with the\n",
      "behavioral characteristics of real-world network communication. This analysis aims to to offer a\n",
      "more functional and application-oriented perspective on the quality of synthetic data, emphasizing\n",
      "its practical utility beyond statistical resemblance. Our main contributions are:\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "×\n",
      "\n",
      "×\n",
      "\n",
      "longer, and producing traces up to 78\n",
      "\n",
      "Synthetic multi-flow sessions. The recurrent structure of NetSSM enables it to produce\n",
      "traces that replicate the behavior of sessions comprised of standalone and interleaved flows\n",
      "with high fidelity. Multi-flow session generation is a new contribution that has been either\n",
      "unexplored or unreliable in prior generators.\n",
      "Capturing flow-state-dependent session events. NetSSM trains using a context window\n",
      "more than 8\n",
      "longer than existing transformer-based\n",
      "raw packet generators, respectively. This enables it to learn from and output traces that\n",
      "capture flow-state-dependent events occurring later in a session that rely on early connection\n",
      "setup, or multiple interactions between flows and/or packets.\n",
      "Superior performance on existing benchmarks. Evaluated on statistical similarity to\n",
      "ground truth traces and accuracy of downstream ML models trained on synthetic data,\n",
      "NetSSM outperforms both the current state-of-the-art traffic attribute generator (NetShare\n",
      "[49]) and raw packet generator (NetDiffusion [21]). For similarity, NetSSM achieves a Jensen-\n",
      "Shannon Divergence of 0.02 versus 0.16 and 0.04 for NetShare and NetDiffusion, respectively.\n",
      "Classification models trained using NetSSM data yield consistently high accuracy. A random\n",
      "forest classifier trained on entirely synthetic NetSSM data achieves an accuracy of 0.97 on\n",
      "held-out ground truth data. In contrast, the same classifiers trained on NetDiffusion and\n",
      "NetShare data yield 0.16 and 0.13 under the same conditions, respectively.\n",
      "Protocol-adherent and behaviorally accurate traffic. NetSSM generates synthetic traffic\n",
      "with high semantic similarity to real traces. Specifically, this traffic (1) shows robust session-\n",
      "level compliance with standard TCP protocol requirements and (2) captures characteristic,\n",
      "application-specific traffic patterns. For (1), NetSSM faithfully replicates correct stateful be-\n",
      "havior (e.g., handshakes, sequence progression, advanced options) and also captures common\n",
      "real-world anomalies (e.g., partial teardowns, conflicting flags). For (2), even when presented\n",
      "\n",
      "2\n",
      "\n",
      "\fwith complex, multi-flow traffic comprised of multiple steps (e.g., setup with content distribu-\n",
      "tion network endpoints before video segment downloads in video streaming traffic), NetSSM\n",
      "replicates these phases with high fidelity.\n",
      "\n",
      "2 RELATED WORK\n",
      "\n",
      "Techniques for generating synthetic network data aim to replicate the characteristics of real-\n",
      "world communication between networked devices, either through higher-level traffic attributes\n",
      "about packets or a session, or raw packet captures. Generation methods can be categorized to two\n",
      "main approaches: traffic attribute generators and raw packet generators.\n",
      "\n",
      "2.1 Traffic attribute generators\n",
      "\n",
      "Traffic attribute generators use either simulation or machine learning (generative adversarial\n",
      "networks (GANs), denoising diffusion, transformers) to produce traffic attributes. Simulation-based\n",
      "approaches were the earliest method for synthesizing network data, operating on a user-defined\n",
      "template that dictates a network’s topology, link specifications, and workload. A user replays\n",
      "existing traces or workloads on this specified configuration, and receives traffic attributes relevant\n",
      "to the simulated communication. Notable efforts in this approach include NS-3 [16], Cisco’s TRex [8],\n",
      "and others [3, 5, 24], which remain popular due to their configurability and relatively low resource\n",
      "footprint for most use cases, meeting many broad, general requirements for synthetic traffic.\n",
      "Unfortunately, prior work [6, 45] has shown that these methods’ simulated traffic typically lacks the\n",
      "variability and unpredictability inherent in actual network conditions. Thus, the resulting output\n",
      "may fail to capture the nuances of real-world traffic exchange.\n",
      "\n",
      "Machine learning-based approaches use time-series prediction models that learn from signals\n",
      "in a given continuous stream of input. This allows them to isolate the fine-grained variations of\n",
      "a single or few traffic attributes and produce data statistically similar to real-world traffic. The\n",
      "data produced by these approaches have been shown to improve the performance of downstream\n",
      "ML-based tasks (e.g., service recognition, anomaly detection). The ML components of these genera-\n",
      "tors also have lower training and inference resource overhead than other methods using higher\n",
      "complexity architectures. As each training sample and generated output is only a single or small\n",
      "set of continuous values, these generators are not limited by input length and can learn from and\n",
      "produce arbitrarily long sequences. In GAN-based approaches, modifications made to the original\n",
      "GAN architecture further prevent these models from “forgetting” dependencies or signals occurring\n",
      "early in a sequence that typically occurs in these models. Lin et al. ’s DoppelGANger [27] was\n",
      "the first GAN-based traffic attribute generator and produces sequences of single traffic attribute\n",
      "values. NetShare, a more recent approach by Yin et al. , builds on DoppelGANger to output more\n",
      "expressive sets of aggregate traffic attributes (e.g., duration, packet count), or more comprehensive\n",
      "sets of packet-level header field values (e.g., time-to-live [TTL], protocol flags) [49]. Zhang et al. ’s\n",
      "NetDiff uses both diffusion and transformers to try to better encode patterns in traffic attributes\n",
      "and use this encoding to better inform generation, specifically for mobile network data [50]. One\n",
      "limitation of these models is that when modeling raw packet contents, they only support learning\n",
      "and generating values from Layer 3 and below (plus transport-layer port numbers) in the OSI model.\n",
      "Thus, they cannot model interactions or attributes in stateful protocols (e.g., TCP).\n",
      "\n",
      "2.2 Raw packet generators\n",
      "\n",
      "Raw packet generators use simulation or machine learning (diffusion, transformers), to output\n",
      "synthetic network traffic in the form of verbose, content level PCAPs. The same simulation-based\n",
      "approaches described in the previous section can be used to produce raw traces, where the simulated\n",
      "communication between nodes is collected (versus summarized to yield traffic attributes) and\n",
      "\n",
      "3\n",
      "\n",
      "\fwritten to a trace. Unfortunately, the same notable shortcoming in expressiveness exists for these\n",
      "simulators when applied in this domain.\n",
      "\n",
      "Machine learning-based approaches train on raw packet data, and generate the byte-level values\n",
      "that comprise the packets of a session. Whereas traffic attribute generators are designed to learn\n",
      "from and capture variations in values over time implicit in a given time series, raw packet generators\n",
      "learn from and capture the inter- and intra-packet relationships contained in a trace’s raw contents,\n",
      "from which traffic attributes can be extracted. Operating on the packet level, these generators\n",
      "can also model protocols at any layer. Evaluated under the same metrics, raw packet generators\n",
      "have been shown to have comparable or better statistical similarity and downstream ML-task\n",
      "performance than traffic attribute generators. Further, the verbose PCAP format outputted by these\n",
      "models is the most versatile for later analysis and feature extraction. Jiang et al. ’s NetDiffusion uses\n",
      "a text-to-image diffusion model with image representations of network traces to generate images\n",
      "following text prompts that define traffic characteristics, which can then be converted back to\n",
      "binary PCAP form for analysis [21]. Qu et al. created TrafficGPT, a transformer decoder model that\n",
      "formulates raw packet generation as a token-based sequence generation task [36]. Given a starting\n",
      "token or prompt of raw traffic bytes in hexadecimal format, TrafficGPT trains on and produces\n",
      "sequences of up to 12,032 tokens, which can then be converted to binary PCAP. Most recently,\n",
      "Chu and Jiang et al. proposed using SSMs, specifically Mamba-1, to generate synthetic traces [7],\n",
      "which our work builds on. A key drawback to existing diffusion and transformer-based raw packet\n",
      "1281\n",
      "generators is their relatively short limit in training context and output length (1,024 and 113\n",
      "packets for NetDiffusion and TrafficGPT, respectively), which may fail to capture target events in\n",
      "sessions. NetDiffusion specifically also requires applying a post-generation heuristic to enforce\n",
      "byte-level corrections for protocol compliance before its traces can be used.\n",
      "\n",
      "−\n",
      "\n",
      "3 STATE SPACE MODELS FOR NETWORK TRAFFIC GENERATION\n",
      "\n",
      "Much communication between networked devices is stateful, and these exchanges may span long\n",
      "sequences of packets for multiple steps (e.g., setup, payload download, teardown). Our choice of\n",
      "Mamba [9, 13], a line of selective structured SSMs, accommodates these characteristics to generate\n",
      "high-fidelity, synthetic network traces. In this section, we provide background on the foundations\n",
      "and properties of SSMs and, specifically, the Mamba model (Section 3.1). We also motivate and\n",
      "compare Mamba against the existing approaches in raw packet generators (Section 3.2).\n",
      "\n",
      "3.1 State Space Models and Mamba\n",
      "\n",
      "SSMs are probabilistic graphical models built on the control engineering concept of a state\n",
      "space [23]. SSMs share the same objective (modeling discrete observations over time) as Hidden\n",
      "Markov Models but differ in that they use continuous, as opposed to discrete, latent variables. Like\n",
      "many deep-learning models, SSMs encode a hidden state that is representative of the prior observed\n",
      "context of an input sequence using recurrent scans. Specifically, SSMs use first-order ordinary linear\n",
      "differential equations to capture the relationship (output) between unobserved variables (state)\n",
      "and a series of continuous observations (input), irrespective of time (i.e., is linear time-invariant\n",
      "[LTI]). As the model observes more data, it encodes a representation of the state that captures the\n",
      "prior context of inputs. This state is then used to calculate an output for a given input and can be\n",
      "both discretized to be calculated as a recurrent neural network (RNN) in linear time and unrolled\n",
      "to a convolutional neural network (CNN) for efficient training. Unfortunately, SSMs suffer from\n",
      "the same pitfall of other recurrently updating networks, in that over time, information about data\n",
      "earlier in a context becomes increasingly compressed in the hidden state, leading to the “vanishing\n",
      "\n",
      "1Using packet lengths of 94/106 tokens from our evaluation case studies, for TrafficGPT’s max gen. length of 12,032 tokens.\n",
      "\n",
      "4\n",
      "\n",
      "\fgradient,” where the model can no longer recall dependencies between inputs. Work by Gu et\n",
      "al. [14] and Voelker et al. [47] offer a possible solution to this challenge by fixing the state matrix\n",
      "used in SSMs, resulting in improved model performance for recalling long-range dependencies.\n",
      "Follow-up works by Gu et al. provide additional improvements to the SSM, improving training\n",
      "efficiency for practical use via convolutional kernel (S4 [15]) and sequence modeling performance\n",
      "via a selection mechanism and a fixed state matrix (Mamba, Mamba-2 [9, 13]).\n",
      "\n",
      "Specifically, Mamba achieves this by implementing two modifications to the general SSM that\n",
      "provide structure and selection. Mamba implements structure by replacing the general SSM state\n",
      "matrix (typically randomly initialized) with a HiPPO matrix [14], introducing a probability measure\n",
      "that dictates how the SSM state is compressed. This, in effect, remedies the vanishing gradient and\n",
      "improves the Mamba SSM’s ability to model long-range dependencies in sequences. For selection,\n",
      "the general LTI SSM lacks expressiveness, i.e., all discrete inputs compressed in the state affect the\n",
      "state with equal weighting. In language modeling, this prevents semantically important “keywords”\n",
      "from more heavily influencing the SSM state and developing a better understanding of input.\n",
      "Mamba improves expressiveness by removing the LTI quality of the general SSM and makes the\n",
      "model time-variant, in which the state is calculated using learned (rather than fixed) functions\n",
      "of the inputs. Mamba’s structure and selection modifications to the general SSM architecture\n",
      "provide competitive performance against conventional transformer-based approaches for sequence\n",
      "modeling, with better scaling (linear versus quadratic).\n",
      "\n",
      "3.2 Why Mamba?\n",
      "\n",
      "We use the Mamba architecture because it is inherently suited to the nature of network data.\n",
      "Specifically, much of networked communication is stateful. Communication between hosts often\n",
      "explicitly depends on the sequential exchange of packets to ensure correct data assembly and\n",
      "to maintain the connection itself. This can be mapped to the recurrent quality of the state-space\n",
      "architecture, in which the model sequentially updates the hidden state on each new input. In\n",
      "our application of Mamba to synthetic trace generation, this provides the means for NetSSM to\n",
      "effectively learn from and produce sessions composed of multiple flows. In contrast, prior traffic\n",
      "attribute and raw packet generators can only operate within the scope of single-flow sessions.\n",
      "\n",
      "The architecture’s convolutional unrolling further complements the network domain by enabling\n",
      "updates to be performed in parallel, helping the model to train over substantially long sequences\n",
      "(e.g., PCAPs) while still implicitly capturing sequential dependencies. As such, Mamba is a much\n",
      "more “natural” fit for modeling network data compared to prior methods for generating raw packet\n",
      "traces. Diffusion-based approaches require abstracting network data to a different domain (images),\n",
      "and further generate traces based on signals from the entire trace, neglecting the sequential delivery\n",
      "of network traffic. Transformer-based models likewise learn input semantics in a completely\n",
      "parallel fashion, where attention is calculated per token of a sequence, against all other tokens\n",
      "in the sequence simultaneously, also not strictly sequentially. The completely parallel nature of\n",
      "computation for either approach is also resource-intensive. NetSSM can generate traces roughly\n",
      "times longer than TrafficGPT. This is a key improvement, as it\n",
      "10\n",
      "allows NetSSM to capture flow-state-dependent sessions events that manifest only after substantial\n",
      "setup has occurred. For instance, in our analysis of Netflix streaming traffic (Section 5.3.3), we\n",
      "found across various collection scenarios that content segments consistently were downloaded\n",
      "only after\n",
      "\n",
      "2,250 packets, when setup had completed.\n",
      "\n",
      "longer than NetDiffusion and 78\n",
      "\n",
      "×\n",
      "\n",
      "×\n",
      "\n",
      "∼\n",
      "\n",
      "4 NETSSM\n",
      "\n",
      "Motivated by shortcomings in existing synthetic network data generators and strong alignment\n",
      "between the operation and capabilities of SSMs and the qualities of networked communications, we\n",
      "\n",
      "5\n",
      "\n",
      "\fFig. 1. Overview of the NetSSM pipeline.\n",
      "\n",
      "present NetSSM, a new raw packet generator. To create NetSSM, we adapt the Mamba-2-backbone,\n",
      "training it from scratch on packets’ raw byte values to synthesize raw packets. Figure 1 provides\n",
      "an overview of the NetSSM pipeline. We provide details for each step of the general pipeline\n",
      "below. Specifics for NetSSM variants used in our evaluation are in their corresponding subsections\n",
      "(Sections 5.1, 5.2, and 5.3, respectively).\n",
      "\n",
      "4.1 Pre-processing Networking Data\n",
      "\n",
      "Input to NetSSM is a sequence of raw bytes comprising the packets in a session trace. Specifically,\n",
      "networking data in PCAP form is parsed to a representative format to align with the token-based,\n",
      "sequence generation objective of the Mamba SSM.\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "0, 255\n",
      "\n",
      "4.1.1 Tokenization. We define a custom tokenizer using Huggingface Tokenizers [34] that one-to-\n",
      "one maps the decimal values of the raw bytes comprising each packet to a corresponding token ID\n",
      "in range\n",
      ". In this way, NetSSM reasons about the raw contents of networking traffic close\n",
      "to its original form. This differs from prior work where network data is represented/tokenized at\n",
      "the flow level [26], as a mix of packet-level and flow attributes [36], or created using a tokenization\n",
      "algorithm that may map raw bytes to tokens using logic suited to a different domain (i.e., WordPiece\n",
      "from NLP) [33]. Our tokenizer also defines label special tokens (e.g., <|facebook|> <|meet|>,\n",
      "<|netflix|>) and a packet special token (<|pkt|>) to allow NetSSM to differentiate between\n",
      "traffic dynamics of different workloads, and packet boundaries in sessions.\n",
      "\n",
      "4.1.2 Creating input data. We extract input to NetSSM from labeled (i.e., the workload/service\n",
      "type of collected traffic is known) collections of PCAPs based on the desired modeling granularity,\n",
      "i.e., single-flow or multi-flow sessions. For single-flow sessions, we split the original PCAP into\n",
      "multiple PCAPs, each corresponding to a comprising flow based on connection (i.e., five-tuple:\n",
      "source IP, source port, destination IP, destination port, IP protocol). No pre-processing is needed\n",
      "for multi-flow sessions. We parse each PCAP to convert the raw bytes comprising each packet to a\n",
      ") in string form, with <|pkt|> special tokens\n",
      "sequence of 8-bit decimal values (i.e., value\n",
      "0, 255\n",
      "]\n",
      "delimiting each packet, and the PCAP’s corresponding label special token prepended to the string.\n",
      "Finally, we use the custom NetSSM tokenizer to tokenize the parsed, string-based PCAP data to a\n",
      "format consumable by NetSSM, producing one input sample for each PCAP in a dataset.\n",
      "\n",
      "∈ [\n",
      "\n",
      "4.2 Pre-training NetSSM\n",
      "\n",
      "Training data created using the above process are fed into NetSSM to learn the semantics of\n",
      "packets, flows, and, correspondingly, sessions. To detail, NetSSM treats generating network traffic\n",
      "data as an unsupervised sequence generation problem. During training, the model optimizes towards\n",
      "the standard cross-entropy loss function which, measures how well the predicted probabilities for\n",
      "a token at a specific index match the correct token. For our experiments with NetSSM, we train\n",
      "the packet generation model using a batch size of one input/training sample, which allows each\n",
      "sample to be 100,000 tokens in length (the maximum length supported for our experiment setup).\n",
      "\n",
      "6\n",
      "\n",
      "Ground TruthPCAPs<|netﬂix|>160......<|pkt|><|pkt|>244Mamba-2NetSSM<|label|> ... <|pkt|>SeedLengthn tokensSyntheticPCAPPre-processingTokenizationPre-trainingGeneration\fThis batch size maximizes the length of packet sequences (i.e., context length) our model learns\n",
      "from, where 100,000 tokens correspond to a context of at least 943 packets (when using packet\n",
      "representations from our case studies).\n",
      "\n",
      "4.3 Generating Synthetic Traces\n",
      "\n",
      "Trace generation requires two arguments: a generation seed and length. The generation seed\n",
      "matches the format of NetSSM’s training samples – a label special token followed by a sequence\n",
      "of any number of full or partial packets represented by their raw-byte contents in decimal form\n",
      "(e.g., <|amazon|> 188 34 203... <|pkt|>). The seed is used to “prompt” NetSSM for generation,\n",
      "equivalent to the “start token” or string in NLP generative models. The generation length dictates\n",
      "the output length (in tokens) NetSSM generates. Using the generation seed, NetSSM’s packet\n",
      "model begins autoregressively generating the raw bytes comprising subsequent packets of the\n",
      "synthetic trace. This procedure continues until the given generation length is satisfied. NetSSM\n",
      "then constructs the intermediate synthetic trace, concatenating the sequence of generated packets\n",
      "represented by their raw bytes in decimal format, and prepending the label special token. This\n",
      "format is then converted to a complete PCAP binary for practical use and downstream evaluation.\n",
      "\n",
      "5 EVALUATION\n",
      "\n",
      "We evaluate the quality of synthetic data produced by NetSSM in three key areas: (1) statistical\n",
      "similarity between generated and real traffic, (2) downstream utility of generated data towards\n",
      "training and improving ML-for-networking models, and (3) semantic similarity between generated\n",
      "and real traffic. Previous traffic attribute and raw packet generators are measured using metrics\n",
      "of statistical similarity and downstream performance. We introduce semantic similarity as an\n",
      "additional aspect that should be considered when evaluating synthetic network data models or\n",
      "systems. For each evaluation, we train a specialized NetSSM model, following the overarching\n",
      "configuration outlined in Section 4.2, to model the traffic dynamics of the respective workloads\n",
      "and objectives. Detailed results and analysis for each case study are presented below.\n",
      "\n",
      "5.1 Statistical Similarity\n",
      "\n",
      "We first evaluate NetSSM using the conventional metric of statistical similarity, which assesses\n",
      "the byte-wise matching between generated synthetic traces and the ground truth traces used for\n",
      "training. In this study, we train a NetSSM model on single-flow traces collected from various\n",
      "types of multimedia traffic. We specifically focus on single-flow traffic because it allows for a more\n",
      "precise and uncontaminated statistical comparison. By isolating individual flows, we can accurately\n",
      "compare the real and synthetic traces based on the specific type of media traffic without interference\n",
      "from other flows or sessions, which would complicate the analysis. Further, prior efforts evaluate\n",
      "the statistical similarity of their approaches on single-flow traffic, allowing us to directly compare\n",
      "NetSSM’s performance with these methods. After training, we generate synthetic traces and\n",
      "compare them to their ground truth counterparts. Our findings show that NetSSM’s synthetic\n",
      "traces exhibit high statistical similarity to real data at the content level (byte-wise comparisons).\n",
      "NetSSM outperforms previous synthetic network trace generation methods in various statistical\n",
      "metrics, highlighting its superior ability to replicate real-world traffic characteristics.\n",
      "\n",
      "5.1.1\n",
      "Setup. We evaluate the statistical similarity of traces produced by (1) a base NetSSM model\n",
      "that trains on and produces continuous sessions, and (2) a fine-tuned version of this base model,\n",
      "optimized to generate packets specific to distinct flow stages. Here, we wish to examine if additional\n",
      "fine-tuning can yield additional performance improvements, particularly in generating these distinct\n",
      "phases or components of authentic network traces. Our rationale stems from the observation that\n",
      "different stages of a network flow, such as the TLS handshake phase (characterized by SYN, SYN-ACK,\n",
      "\n",
      "7\n",
      "\n",
      "\fTable 1. Overview of datasets used to train and evaluate NetSSM.\n",
      "\n",
      "Dataset\n",
      "\n",
      "Evaluation Task(s)\n",
      "\n",
      "Source\n",
      "\n",
      "Content Type\n",
      "\n",
      "Size\n",
      "\n",
      "Classification\n",
      "\n",
      "# uniqe sub-groups\n",
      "\n",
      "Raw\n",
      "\n",
      "# Captures\n",
      "\n",
      "Multimedia Traffic\n",
      "\n",
      "Statistical Sim.\n",
      "Downstream Util.\n",
      "\n",
      "Bronzino et al. [4]\n",
      "MacMillan et al. [32] Video Conferencing\n",
      "Jiang et al. [22]\n",
      "\n",
      "Video Streaming\n",
      "\n",
      "Social Media\n",
      "\n",
      "Netflix Streaming\n",
      "\n",
      "Semantic Sim.\n",
      "\n",
      "Bronzino et al. [4]\n",
      "\n",
      "Video Streaming\n",
      "\n",
      "* composed of single flows.\n",
      "\n",
      "4\n",
      "3\n",
      "3\n",
      "\n",
      "1\n",
      "\n",
      "6.36 GiB\n",
      "17.36 GiB\n",
      "5.40 GiB\n",
      "\n",
      "216.36 GiB\n",
      "\n",
      "10,032∗\n",
      "13,911∗\n",
      "3,896∗\n",
      "\n",
      "5,882†\n",
      "\n",
      "† composed of multiple flows.\n",
      "\n",
      "and ACK packets) and the data transmission phase (dominated by PUSH and ACK packets), exhibit\n",
      "unique patterns and behaviors. Additional, fine-tuning can be especially useful for applications\n",
      "that require synthetic data tailored to specific flow stages, such as generating synthetic traces for\n",
      "data transmission or session termination to study key network behaviors (e.g., session termination\n",
      "indicators). We detail the setup for either model below.\n",
      "Base model. We train our NetSSM model for single-flow generation using a dataset comprised\n",
      "of session traces collected from 10 distinct applications, falling into three overarching categories:\n",
      "video streaming [4], video conferencing [32], and social media [22]. Table 1 presents an overview\n",
      "of this data. We first pre-process the data from each source, using pcap-splitter [40] to split\n",
      "original PCAPs into their comprising single-flow PCAPs based on 5-tuple, and parse them into\n",
      "the string representations of their raw bytes in decimal form, as described in Section 4.1.2. We fix\n",
      "each packet to be represented by 94 tokens, corresponding to the maximum practical lengths of\n",
      "the Ethernet (14 bytes), IPv4 (20 bytes excluding options), and TCP headers (60 bytes including\n",
      "TCP extensions). To fit the scope of this case study, we train this NetSSM variant on TCP traffic\n",
      "only, as session handshakes/setup predominantly requires the state maintaining quality of a TCP\n",
      "connection. We do not consider TCP payload in this case study, as this data is becoming increasingly\n",
      "encrypted [11, 17, 19] and thus would be noise our model would not learn from.\n",
      "\n",
      "We create a custom tokenizer following the configuration described in Section 4.1.1, defining 10\n",
      "label special tokens corresponding to the 10 distinct applications in our dataset. We then tokenize\n",
      "all string representations resulting from splitting our data to their single-flows. This results in a\n",
      "final dataset of 27,839 samples. We pre-train the single-flow packet NetSSM model on the created\n",
      "dataset using a single NVIDIA A40 48GB GPU for 30 epochs with a gradient clip value of 1.0 and\n",
      "4. All other AdamW parameters are left at default.\n",
      "AdamW optimizer with learning rate of 5\n",
      "We use the same configuration as the smallest publicly available 130 million parameter pre-trained\n",
      "Mamba-2 (dimension of 768, 24 layers), but instead use our custom tokenizer. The training process\n",
      "results in a model with cross-entropy loss converging at 0.42 nats.\n",
      "\n",
      "10−\n",
      "\n",
      "×\n",
      "\n",
      "We generate traces using the process detailed in Section 4.3 with the trained NetSSM model,\n",
      "producing a corresponding synthetic trace for each real trace used during training. Specifically,\n",
      "we use the first packet from the real training trace, represented in decimal form, along with its\n",
      "corresponding label as the seed (e.g., <|amazon|> 188 34 203... <|pkt|>). We set the generation\n",
      "length to be the number of tokens needed to represent the total number of packets of a corresponding\n",
      "real trace. This ensures that the generated trace contains a similar number of packets to the real\n",
      "trace, providing a consistent basis for evaluating the synthetic version’s statistical similarity.\n",
      "Fine-tuned model. We train the fine-tuned NetSSM model by first creating sub-datasets from\n",
      "the original dataset described above, that isolate the packets relevant to specific stages of a flow’s\n",
      "lifetime. These sub-datasets focus on distinct phases of network communication, such as session\n",
      "initiation, data exchange, and session termination. We then use these phase-specific data to fine-\n",
      "tune the base single-flow NetSSM model from the 30-epoch pre-training checkpoint, using the\n",
      "same next-token prediction objective as the original model but with phase-specific packets as\n",
      "\n",
      "8\n",
      "\n",
      "\fTable 2. Byte-wise statistical similarity for traces of various generators. NetSSM generated traces are\n",
      "most statistically similar to real traffic, with both its base and fine-tuned versions achieving at least 2\n",
      "lower\n",
      "divergence and distance values across all metrics as compared to the next best method.\n",
      "\n",
      "×\n",
      "\n",
      "Generation Method\n",
      "\n",
      "Random Generation (flow statistics)\n",
      "Random Generation (raw packets)\n",
      "NetShare\n",
      "NetDiffusion†\n",
      "TrafficGPT*\n",
      "NetSSM (base)\n",
      "NetSSM (fine-tuned)\n",
      "\n",
      "† Post-generation correction applied.\n",
      "\n",
      "Jensen-Shannon Divergence\n",
      "\n",
      "Total Variation Distance\n",
      "\n",
      "Hellinger Distance\n",
      "\n",
      "↓\n",
      "\n",
      "↓\n",
      "\n",
      "↓\n",
      "\n",
      "Evaluation Metric\n",
      "\n",
      "0.67\n",
      "0.82\n",
      "0.16\n",
      "0.04\n",
      "0.16*\n",
      "0.02\n",
      "0.02\n",
      "\n",
      "0.80\n",
      "0.99\n",
      "0.16\n",
      "0.04\n",
      "—\n",
      "0.02\n",
      "0.01\n",
      "\n",
      "0.76\n",
      "0.95\n",
      "0.18\n",
      "0.05\n",
      "—\n",
      "0.02\n",
      "0.02\n",
      "\n",
      "* As reported in [36].\n",
      "\n",
      "input. This allows the model to capture the intra-packet and flow dynamics unique to each phase,\n",
      "leading to improvements in both the quality and flexibility of output. When generating data with\n",
      "the fine-tuned models, We chain outputs from one phase-specific model to the next. Specifically,\n",
      "the final packet produced by the handshake model serves as the seed for the subsequent data\n",
      "transmission model, while the final packet generated by the data transmission model acts as the\n",
      "seed for the subsequent session teardown model.\n",
      "\n",
      "5.1.2 Content-Level Results. We evaluate NetSSM’s generation fidelity by analyzing the statistical\n",
      "similarity between the generated and real traffic data at the content level. This similarity is quantified\n",
      "using three key metrics: Jensen-Shannon Divergence (JSD), Total Variation Distance (TVD), and\n",
      "Hellinger Distance (HD), which measure distributional distances, with lower values indicating\n",
      "closer alignment to real-world data.\n",
      "\n",
      "For NetSSM and NetDiffusion, we perform byte-wise comparisons by converting the generated\n",
      "and ground truth PCAPs into standardized binary representations using nPrint [18], which supports\n",
      "up to 1,024 packets per PCAP (the maximum for NetDiffusion). We then consider the three statistical\n",
      "measures across all TCP header values, to enable uniform comparison. For TrafficGPT, we rely on\n",
      "the results reported in their work [36], as they do not provide open-source code, limiting direct\n",
      "comparison. For NetShare, which generates traffic attributes, we derive the ground truth traffic\n",
      "attributes from the real traces and compute the statistical distances between these and the generated\n",
      "traffic attributes. Though NetShare generate traffic attributes and NetDiffusion, TrafficGPT, and\n",
      "NetSSM generate raw traces, it is still appropriate to compare their resulting statistical measures\n",
      "as they measure distributional distances rather than absolute values. This ensures the evaluation\n",
      "captures how closely each model’s generated traffic replicates real-world traffic patterns within\n",
      "its respective granularity. Finally, we include two lower-bound baselines representing worst-case\n",
      "scenarios: random generation of flow statistics and raw packets, which serve as benchmarks for\n",
      "poor fidelity. Table 2 summarizes the results of the comparisons.\n",
      "\n",
      "We find that NetSSM consistently outperforms the other methods in all metrics. As expected,\n",
      "random generation of traffic attributes and raw packets produces the highest distances, with the\n",
      "JSD, TVD, and HD values ranging from 0.67 to 0.99. NetShare achieves moderate performance with\n",
      "HD of 0.18 and 0.16 for both the JSD and TVD, but falls short in accurately capturing fine-grained\n",
      "packet details. NetDiffusion performs well with post-generation correction applied, achieving low\n",
      "distances (JSD of 0.04) but still lags behind NetSSM. TrafficGPT, while comparable to NetShare in\n",
      "some cases, lacks complete data for comparison. NetSSM demonstrates the highest fidelity, with\n",
      "distance values as low as 0.01 to 0.02, highlighting its ability to generate synthetic traces that at\n",
      "the byte-level, closely resemble real traffic.\n",
      "\n",
      "9\n",
      "\n",
      "\f(a)\n",
      "\n",
      "(b)\n",
      "\n",
      "(c)\n",
      "\n",
      "(d)\n",
      "\n",
      "Fig. 2. Accuracy of random forest classifiers trained on varying proportions of real/synthetic data.\n",
      "Models trained on NetSSM data demonstrate significant improvements in test accuracy compared to both\n",
      "NetShare and NetDiffusion. Colored shading highlights areas where the corresponding model achieves higher\n",
      "accuracy than the next best baseline.\n",
      "\n",
      "5.2 Downstream Utility\n",
      "\n",
      "We next examine the performance of ML-for-networking models trained with synthetic data\n",
      "to assess the quality of this data in practical applications. While measures of statistical similarity\n",
      "provide insight into how closely synthetic data replicates the raw composition of real-world data,\n",
      "they should not be the only metrics used to evaluate the quality of generated traffic. Specifically,\n",
      "when calculated at the high-granularity (e.g., at the byte-level as detailed in the previous section),\n",
      "these measures may not capture how well synthetic data can be used in application. Thus, examining\n",
      "how well synthetic data can be used in various downstream tasks (e.g., network traffic classification,\n",
      "anomaly detection, or intrusion detection) provides further validation of data fidelity.\n",
      "\n",
      "Specifically, we train two classifiers that focus on (1) application-level classification, and (2)\n",
      "service-type-level classification. For (1), the objective is to classify network traffic into specific,\n",
      "fine-grained applications (e.g., differentiating YouTube from Amazon traffic). For (2), we group\n",
      "traffic into broader categories such as differentiating between media types (e.g., video streaming,\n",
      "web browsing), that encapsulates more general traffic patterns.\n",
      "\n",
      "5.2.1\n",
      "Setup. The model pipeline, hardware, and parameters of this case study follow exactly with\n",
      "the setup described in Section 5.1.1. To test the utility of synthetic data in augmenting model\n",
      "training, we create downstream training datasets composed of both real data, and synthetic data\n",
      "from NetSSM, NetDiffusion, and NetShare. These datasets have different mixing rates that represent\n",
      "the proportion of synthetic data used to replace original real data in the dataset. We create a new\n",
      "dataset at each 10% inclusive increments, resulting in 33 downstream training datasets. For example,\n",
      "a downstream training dataset with a 20% mixing rate contains 80% real data, and 20% synthetic\n",
      "data. We train three different types of ML classifiers (Decision Trees [DT], Random Forest [RF],\n",
      "and Support Vector Machines [SVM]) on these downstream datasets, resulting in a corresponding\n",
      "33 models. Finally, we test each models’ performance on held out samples of completely real, and\n",
      "completely synthetic data to assess their performance and generalization across different training\n",
      "and testing environments. In each scenario, we analyze if a generator’s synthetic data can maintain\n",
      "and/or improve classification accuracy when mixed into the training data at various rates.\n",
      "\n",
      "5.2.2 Results. Figure 2 shows the accuracy of Random Forest (RF) models trained for application\n",
      "and service-type-level traffic classification using the mixed downstream datasets from NetSSM,\n",
      "NetDiffusion and NetShare, and tested on application and both completely real, and completely\n",
      "synthetic data. The vertical dashed line in each sub-figure highlights the maximum accuracy gain in\n",
      "each scenario. We focus on only RF model performance to simplify the presentation, as the results\n",
      "\n",
      "10\n",
      "\n",
      "0.00.51.0MixingRate0.000.250.500.751.00AccuracyΔAcc.:trainon100%syndata:0.818AppLevel;TestedonRealData0.00.51.0MixingRate0.000.250.500.751.00ΔAcc.:trainon100%syndata:0.329ServiceTypeLevel;TestedonRealData0.00.51.0MixingRate0.000.250.500.751.00ΔAcc.:trainon100%syndata:0.858AppLevel;TestedonSynData0.00.51.0MixingRate0.000.250.500.751.00AccuracyΔAcc.:trainon100%syndata:0.471ServiceTypeLevel;TestedonSynDataRF,NETSSMRF,NetDiffusionRF,NetShare\ffrom other models (e.g., Decision Trees and SVMs) exhibit similar patterns. Comprehensive results\n",
      "for these additional models, along with results from the non-fine-tuned version, are in Appendix A.\n",
      "Testing on Real Data. We first examine the performance our downstream models when tested\n",
      "on completely real data. Figures 2a and 2b visualize the results. Models trained on NetSSM data\n",
      "maintain consistently high classification accuracy across all mixing rates, even when the training set\n",
      "consists entirely of synthetic data. We observe substantial accuracy gain over existing approaches,\n",
      "with an improvement of approximately 0.818 and 0.329 at the application and service-type-level,\n",
      "respectively, when synthetic data constitutes 100% of the training set. This demonstrates NetSSM’s\n",
      "ability to generate realistic synthetic traffic that (1) preserves fine-grained distinctions between\n",
      "traffic patterns critical for application-level classification and (2) effectively replicates high-level\n",
      "traffic behaviors that are helpful for service-type-level classification.\n",
      "\n",
      "We observe that models trained on NetDiffusion data, the next best generator for the classification\n",
      "task, experience significant drops in accuracy for either task as mixing rate increases. In application-\n",
      "level classification, there is notable decrease in model accuracy after the 60% mixing rate, with\n",
      "the gap widening further as synthetic data becomes the sole training input. For service-type\n",
      "classification, NetDiffusion-data-trained models performs well up to an 80% mixing rate but suffer\n",
      "rapid decline in accuracy as more real data is replaced with synthetic data. This suggests that\n",
      "while NetDiffusion is more effective at capturing broader patterns, it struggles to replicate more\n",
      "fine-grained, application specific interactions.\n",
      "\n",
      "Finally, models trained on NetShare data, which consists of only traffic attributes, perform\n",
      "the worst on both tasks, with accuracy sharply declining even at low mixing rates. The lack of\n",
      "detailed packet-level data in NetShare’s output makes it ineffective for use in tasks where granular\n",
      "distinctions between traffic applications are essential. At the service-type-level, models similarly\n",
      "show reinforcing the idea that traffic attributes alone are insufficient for accurate classification.\n",
      "Despite some improvement when synthetic data dominates the training set, NetShare consistently\n",
      "lags behind the other models, further emphasizing the importance of generating detailed packet-\n",
      "level data to achieve high fidelity in traffic classification.\n",
      "Testing on Synthetic Data. Testing our downstream models on completely synthetic data yields\n",
      "similar results, as shown in Figures 2c and 2d. NetSSM consistently achieves near-perfect accuracy,\n",
      "ranging from 0.94 to 0.97 for application-level classification and from 0.99 to 1.00 for service-type-\n",
      "level classification, regardless of the mixing rate. This represents improvements of 0.858 and 0.471 in\n",
      "either task over the next best synthetic data generator. This demonstrates that NetSSM’s generated\n",
      "traces maintain internal coherence, and do not introduce artificial signals that degrade downstream\n",
      "model performance. While models trained on NetDiffusion and NetShare data perform relatively\n",
      "well at higher mixing rates, they experience notable drops in accuracy at lower mixing rates. For\n",
      "application-level classification, we observe accuracies as low as 0.10 and 0.12 for NetShare and\n",
      "NetDiffusion, respectively. For service-type-level classification, we observe minimum accuracies of\n",
      "0.17 and 0.52 for NetShare and NetDiffusion, respectively.\n",
      "\n",
      "Finally, we conduct ablations with NetSSM data that exclude the first packet in both the generated\n",
      "and real traces during downstream model training and inference. We do this to ensure that the\n",
      "downstream models were not learning solely based on the first packet, which is used as a seed from\n",
      "the real trace to generate the remainder of the synthetic trace in NetSSM. The results, presented\n",
      "in Figure 6 (and Appendix A), show that excluding the seed packet has no significant impact on\n",
      "downstream models’ performance, confirming the robustness and generalization capability of\n",
      "NetSSM’s generated traffic the beyond initial packet dependency.\n",
      "\n",
      "Overall, we find that at higher mixing rates (particularly when synthetic data comprises 80-100%\n",
      "of the training data) NetSSM data provides superior performance compared to both NetDiffu-\n",
      "sion and NetShare data. NetSSM-generated data can effectively replace real-world data in both\n",
      "\n",
      "11\n",
      "\n",
      "\fapplication and service-type-level ML classification tasks without significant losses in accuracy,\n",
      "verifying utility in downstream tasks. This resilience is particularly important when synthetic data\n",
      "dominates the training set, as models trained on NetSSM-generated data appear to remain robust,\n",
      "and can generalize well even when synthetic data constitutes the majority of the input.\n",
      "\n",
      "5.3 Semantic Similarity\n",
      "\n",
      "The existing statistical similarity and downstream utility measures for network data generators\n",
      "are largely motivated by how well these data can improve downstream ML-for-networking model\n",
      "performance. This approach may be acceptable for traffic attribute generators as their produced\n",
      "sequences are independent in scope, e.g., NetShare [49] is trained on independent sequences of\n",
      "packet sizes, and observed IP protocols in a ground truth flow to produce independent sequences\n",
      "of the same values for a synthetic flow. Here, while in reality these fields may influence each other,\n",
      "the model learns them as separate entities. However, raw packet generators should be evaluated\n",
      "more rigorously, as the surrounding, or preceding raw byte values in a packet/capture directly\n",
      "affect the generation of trace as a whole (e.g., for diffusion, and transformers/SSMs, respectively). If\n",
      "traffic attribute can be extracted from a generated trace but the capture itself cannot be manually\n",
      "examined by a packet analysis tool, this is likely not “good” synthetic data. Similarly, if a generated\n",
      "PCAP is parsable by Wireshark, but the contained communication setup between flows is out of\n",
      "order or incorrect, this traffic should not be considered for replacing real-world data.\n",
      "\n",
      "To this end, we evaluate NetSSM’s ability to produce semantically similar synthetic network\n",
      "traffic that (1) is TCP flow and session-compliant, i.e., maintains correct and realistic TCP state\n",
      "transitions across the span of a trace, and (2) captures the implicit characteristics for a given\n",
      "networked communication workload. In either analysis, we additionally evaluate NetSSM’s ability\n",
      "to produce multi-flow synthetic traces, specifically Netflix video streaming traffic, produced by a\n",
      "new NetSSM model further detailed in this section. For (1), we analyze both synthetic single-flow\n",
      "traffic generated in the previous section and the multi-flow Netflix traffic. For (2), we examine the\n",
      "multi-flow communication between end hosts and Netflix video streaming servers in our synthetic\n",
      "traces. We analyze the sending patterns between hosts and verify that the generated traces contain\n",
      "the distinctive segment download patterns of real Netflix traffic. We also verify that NetSSM can\n",
      "maintain the generation of these patterns when prompted with packets corresponding to traces\n",
      "collected under different network conditions.\n",
      "\n",
      "5.3.1\n",
      "Setup. We train NetSSM on multi-flow traffic of Netflix video streaming sessions collected\n",
      "by Bronzino et al. [4] from 66 real-world, home devices in the United States and France, with link\n",
      "capacities spanning 18 Mbps to 1 Gbps. Table 1 (bottom) provides an overview of this data. We train\n",
      "on only a subset of this data (5,882 captures) due to access constraints. We do not split captures their\n",
      "comprising single-flows, but perform all other pre-processing in an identical manner as described\n",
      "in Section 5.1.1. Training sequences consist of both TCP and UDP packets, and we further extend\n",
      "the packet representation used for this model to 106 tokens, where the 12 additional tokens as\n",
      "compared to the NetSSM variant described in Section 5.1 allow NetSSM to learn information from\n",
      "DNS headers for requests and responses present in session setup. All TCP and UDP payload is\n",
      "discarded for the reasons described in the previous case study setup, in addition to the increasing\n",
      "prevalence of encrypted DNS [12, 31, 38]. Tokenization of our training sequences follows the\n",
      "process of the statistical similarity pipeline, resulting in a dataset of 5,882 samples. Finally, we\n",
      "pre-train the multi-flow model using the same training parameters and hardware as described in\n",
      "Section 5.1.1, for 30 epochs, where cross-entropy loss converged at 0.33 nats.\n",
      "\n",
      "We then use this model to generate synthetic multi-flow network traffic. Specifically, we focus\n",
      "on examining NetSSM’s ability to capture the sending/receiving of Dynamic Adaptive Streaming\n",
      "\n",
      "12\n",
      "\n",
      "\fover HTTP [42] segments containing Netflix audio and video content, as described in the paper\n",
      "for this dataset [4], across the various collection scenarios present in the ground truth data. We\n",
      "empirically observe in the traces used to train our multi-flow NetSSM variant that the video stream\n",
      "2,250 packets.\n",
      "traffic sending patterns described in the previous section become discernible after\n",
      "Accordingly, we use a context length of 238,500 tokens (106 tokens per packet) to prompt our\n",
      "model for generation, and generation length of 10,600,000 tokens, or 10,000 packets. We choose this\n",
      "generation length to balance evaluating NetSSM’s expressiveness over a sufficiently long context,\n",
      "and time efficiency (each 10,000 packet synthetic trace takes\n",
      "20 minutes to generate). Finally, we\n",
      "randomly sample 100 PCAPs from the ground truth set, extract the first 2,250 packet contexts from\n",
      "each, and use this context to generate their corresponding synthetic captures. For analysis, we\n",
      "compare the generated traces against their ground truth counterparts, truncated to a matching\n",
      "length of 10,000 packets. We present the results of this analysis in the following subsections.\n",
      "\n",
      "∼\n",
      "\n",
      "∼\n",
      "\n",
      "5.3.2 TCP Session Compliance. Prior evaluations have focused on statistical fidelity; we further\n",
      "dissect NetSSM’s ability to reproduce correct and realistic TCP state transitions through a dedicated\n",
      "protocol compliance analysis on the session level. TCP is a stateful protocol that requires accurate\n",
      "ordering and flag usage (e.g., SYN, ACK, FIN, RST), adherence to handshake procedures, and consistent\n",
      "usage of options like Maximum Segment Size (MSS) and Selective Acknowledgment (SACK). In\n",
      "real network traffic, these behaviors may deviate from strict textbook implementations due to NAT\n",
      "devices, middlebox interventions, or partial captures. By comparing NetSSM-generated traces\n",
      "with real PCAPs (i.e., ground truth), we provide an in-depth assessment of how closely NetSSM\n",
      "approximates legitimate TCP operations while capturing the natural diversity and anomalies\n",
      "observed in practice. We also compare single-flow synthetic traces generated by NetDiffusion,\n",
      "but do not apply heuristic-based post-generation corrections, as our goal is to assess the intrinsic\n",
      "capability of each generative model rather than the thoroughness of external rule-based corrections.\n",
      "The same heuristic layer could be added to NetSSM’s output, but this would obscure how effectively\n",
      "the underlying model itself enforces TCP compliance. By omitting these extra adjustments for both\n",
      "methods, we obtain a clearer evaluation of how accurately each generator handles fundamental\n",
      "TCP requirements on its own.\n",
      "\n",
      "We consider two sets of real PCAPs and two corresponding sets of synthetic PCAPs generated\n",
      "by NetSSM, separating the evaluation into single-flow and multi-flow traffic. In the multi-flow\n",
      "evaluation, each PCAP contains multiple concurrent TCP flows, simulating common scenarios\n",
      "such as video streaming sessions accompanied by DNS lookups or additional data retrievals. In\n",
      "the single-flow evaluation, each PCAP strictly contains a single TCP flow for more controlled,\n",
      "fine-grained analysis. For both real and synthetic PCAPs, we parse each trace using a custom TCP\n",
      "compliance checker that inspects flags, sequence numbers, acknowledgment numbers, and TCP\n",
      "options. Tables 3 and 4 present the results of this checker, with the first summarizing pass/fail or\n",
      "presence checks, and the second displaying aggregate counts of the encountered TCP options.\n",
      "Handshake Correctness and Basic IP Compliance. Both synthetic (NetSSM-generated) and\n",
      "real multi-flow traces show a perfect rate of three-way handshakes (100 of 100). This demonstrates\n",
      "that NetSSM accurately reproduces the necessary SYN\n",
      "ACK exchange in concurrent-\n",
      "connection environments without failing to progress any session out of the initial state. Single-flow\n",
      "traces exhibit lower but still high handshake correctness, with NetSSM achieving 517 correct\n",
      "handshakes out of 803 and the real dataset showing 777 out of 1,108. This result can be partially\n",
      "attributed to truncated single-flow captures, either in the real set or in generation. At the IP layer,\n",
      "real multi-flow traces maintain a flawless 100 of 100 IPv4 correctness, while NetSSM’s synthetic\n",
      "multi-flow traces fall marginally short at 92 of 100. Nonetheless, both single-flow datasets meet full\n",
      "\n",
      "SYN-ACK\n",
      "\n",
      "→\n",
      "\n",
      "→\n",
      "\n",
      "13\n",
      "\n",
      "\fTable 3. TCP session compliance for real/synthetic data. NetSSM reliably replicates handshakes, se-\n",
      "quence tracking, and advanced options, and captures real-world anomalies (e.g., resets, partial teardowns).\n",
      "NetDiffusion, without heuristic fixes, struggles with core TCP states.\n",
      "\n",
      "Metric\n",
      "\n",
      "Correct handshakes found\n",
      "Correct IPv4 version\n",
      "ACK progress\n",
      "SEQ progress\n",
      "FIN seen\n",
      "FIN-ACK observed\n",
      "\n",
      "Multi-Flow\n",
      "\n",
      "Gen. (NetSSM) (n =100)* Real (n=100)\n",
      "\n",
      "100.0%\n",
      "92.0%\n",
      "99.0%\n",
      "99.0%\n",
      "63.0%\n",
      "3.0%\n",
      "\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "13.0%\n",
      "7.0%\n",
      "\n",
      "Gen. (NetSSM) (n=803)\n",
      "64.4%\n",
      "100.0%\n",
      "63.1%\n",
      "60.6%\n",
      "15.3%\n",
      "3.1%\n",
      "\n",
      "Single-Flow\n",
      "\n",
      "Real (n=1108)\n",
      "70.2%\n",
      "100.0%\n",
      "69.6%\n",
      "68.9%\n",
      "5.9%\n",
      "0.5%\n",
      "\n",
      "Gen. (NetDiff.) (n=1000)†\n",
      "0.0%\n",
      "100.0%\n",
      "0.0%\n",
      "0.0%\n",
      "51.6%\n",
      "0.0%\n",
      "\n",
      "(a) Metrics reflecting correct TCP session behavior. Higher percentages indicate better compliance.\n",
      "\n",
      "Metric\n",
      "\n",
      "Unexpected SYN after estab.\n",
      "RST in established state\n",
      "Timestamps disappeared\n",
      "Conflicting flags\n",
      "ACK beyond sent data\n",
      "MSS outside handshake\n",
      "WScale outside handshake\n",
      "SAck used w/o OK\n",
      "\n",
      "Multi-Flow\n",
      "\n",
      "Single-Flow\n",
      "\n",
      "Gen. (NetSSM) (n=100)\n",
      "\n",
      "Real (n=100)\n",
      "\n",
      "Gen. (NetSSM) (n=803)\n",
      "\n",
      "Real (n=1108)\n",
      "\n",
      "Gen. (NetDiff.) (n=1000)\n",
      "\n",
      "6.0%\n",
      "6.0%\n",
      "5.0%\n",
      "57.0%\n",
      "99.0%\n",
      "22.0%\n",
      "22.0%\n",
      "58.0%\n",
      "\n",
      "0.0%\n",
      "22.0%\n",
      "10.0%\n",
      "0.0%\n",
      "100.0%\n",
      "17.0%\n",
      "17.0%\n",
      "14.0%\n",
      "\n",
      "0.0%\n",
      "35.7%\n",
      "23.2%\n",
      "0.5%\n",
      "56.3%\n",
      "3.4%\n",
      "3.4%\n",
      "1.1%\n",
      "\n",
      "0.0%\n",
      "35.7%\n",
      "24.5%\n",
      "0.0%\n",
      "46.9%\n",
      "2.0%\n",
      "2.0%\n",
      "2.9%\n",
      "\n",
      "0.0%\n",
      "0.0%\n",
      "0.0%\n",
      "34.4%\n",
      "0.0%\n",
      "0.0%\n",
      "0.0%\n",
      "18.7%\n",
      "\n",
      "(b) Metrics reflecting anomalies or deviations in TCP behavior. Lower percentages indicate better compliance.\n",
      "\n",
      "No post-gen. fixes applied to NetDiffusion.\n",
      "\n",
      "†\n",
      "\n",
      "* 𝑁 ≔ # of PCAPs compared.\n",
      "\n",
      "compliance (803 of 803 synthetic, 1,108 of 1,108 real), indicating that NetSSM rarely deviates from\n",
      "the IPv4 version when generating simpler one-to-one flows.\n",
      "SEQ and ACK Progression. Most synthetic and real multi-flow traces display consistent forward\n",
      "progress for SEQ and ACK (99 of 100 and 100 of 100, respectively). Similarly, in single-flows, NetSSM\n",
      "achieves solid performance (507 of 803 and 487 of 803 for ACK and SEQ, respectively), demonstrat-\n",
      "ing that it typically avoids rewinding sequence numbers or acknowledging data never observed.\n",
      "Discrepancies from 100% in single-flow sets may occur when the generative model produces abrupt\n",
      "transitions or unusual corner cases that do not align with real flow expansions.\n",
      "FIN Behavior and Teardown. Graceful TCP teardown typically involves FIN and ACK exchanges.\n",
      "We observe NetSSM’s multi-flow traces contain FIN segments in 63 of 100 cases, substantially\n",
      "higher than the 13 of 100 in the real multi-flow dataset. This may be explained by the fact that\n",
      "our real captures often end abruptly or fail to see FIN segments if preempted. However, FIN-ACK\n",
      "occurrences remain comparatively low on both sides (three of 100 for synthetic vs. seven of 100\n",
      "for real), reflecting that full bidirectional closures are often incomplete in real-world recordings.\n",
      "Single-flow captures from NetSSM also show a higher FIN presence (123 of 803) relative to the real\n",
      "set (65 of 1,108), reinforcing the idea that synthetic flows commonly seek a finite conclusion. While\n",
      "the NetSSM generator tends to inject FIN states more proactively, this does not always culminate\n",
      "in the final ACK needed for a perfectly closed connection. Nevertheless, such partial-teardown\n",
      "patterns mirror typical divergences seen in real sessions.\n",
      "RST States and Unexpected Flags. Abnormal flags such as RST or conflicting flags (e.g., FIN with\n",
      "SYN) can signal mid-connection resets, error conditions, or rare misconfigurations. In the multi-flow\n",
      "dataset, real traces display 22 of 100 instances that contain RST in the established state, whereas\n",
      "NetSSM only displays six instances. To contrast, in single-flow data, synthetic captures feature 287\n",
      "RST occurrences across 803 instances, while real single-flow instances see 396 out of 1,108, indicating\n",
      "that abrupt resets are a frequent real-world phenomenon, especially in scenarios with ephemeral or\n",
      "forcibly terminated sessions. Conflicting flags are almost exclusively found in synthetic multi-flow\n",
      "\n",
      "14\n",
      "\n",
      "\fTable 4. TCP option counts for real/synthetic data. Comparative counts of major TCP options across\n",
      "multi-flow and single-flow traces. NetSSM aligns best with real traffic as compared to NetDiffusion.\n",
      "\n",
      "TCP Option\n",
      "\n",
      "MSS\n",
      "WScale\n",
      "SAckOK\n",
      "Timestamp\n",
      "SAck\n",
      "\n",
      "Multi-Flow\n",
      "\n",
      "Single-Flow\n",
      "\n",
      "Generated (NetSSM)\n",
      "\n",
      "Real\n",
      "\n",
      "Generated (NetSSM)\n",
      "\n",
      "Real\n",
      "\n",
      "Generated (NetDiffusion)\n",
      "\n",
      "47,607\n",
      "47,402\n",
      "47,333\n",
      "786,569\n",
      "32,251\n",
      "\n",
      "10,844\n",
      "10,824\n",
      "10,824\n",
      "718,878\n",
      "75,353\n",
      "\n",
      "2,183\n",
      "2,181\n",
      "2,165\n",
      "39,993\n",
      "1,025\n",
      "\n",
      "1,654\n",
      "1,654\n",
      "1,638\n",
      "1,856,168\n",
      "39,097\n",
      "\n",
      "47,497\n",
      "66,981\n",
      "350,189\n",
      "451,055\n",
      "132,688\n",
      "\n",
      "traces (57 of 100), suggesting that NetSSM’s concurrency logic sometimes merges states or “double-\n",
      "flags” certain segments under complex conditions. Although real captures typically avoid these\n",
      "direct conflicts, their presence in synthetic flows can be beneficial for testing anomaly detection\n",
      "systems, as real devices or middleboxes can occasionally emit similarly malformed packets in\n",
      "pathological cases.\n",
      "Timestamps and Option Usage Outside the Handshake. TCP options convey various ne-\n",
      "gotiation parameters (e.g., MSS, Window Scale, SACK Permitted). Table 3 shows that timestamps\n",
      "disappear at times (five of 100 NetSSM and 10 of 100 real in multi-flow traces; 186 of 803 NetSSM\n",
      "and 271 of 1,108 real in single-flow traces), reflecting partial captures or toggled timestamp usage.\n",
      "This is understandable as real systems may fail to consistently include timestamps in every packet\n",
      "once a connection is established. Regarding MSS and WScale usage, 22 of 100 NetSSM multi-flow\n",
      "instances include these options beyond the initial handshake, a figure close to the 17 of 100 in real\n",
      "multi-flow traces. Single-flow sessions likewise display 27 of 803 instances in NetSSM and 22 of\n",
      "1,108 in real traces, respectively. Although specifying MSS or WScale outside the SYN handshake is\n",
      "often considered non-standard, both synthetic and real data confirm that such anomalies occur in\n",
      "real-world traffic. Finally, “SACK used w/o OK” emerges in 58 of 100 NetSSM multi-flow instances\n",
      "and 14 of 100 real multi-flow traces, respectively, and 9 of 803 NetSSM single-flow and 32 of\n",
      "1,108 real single-flow traces, respectively. While ideally SACK blocks should appear only if SACK\n",
      "Permitted is negotiated, real network traces also show sporadic violations.\n",
      "\n",
      "Table 4 shows that NetSSM’s multi-flow traces exhibit significantly higher raw counts for MSS,\n",
      "WScale, and SAckOK compared to their real counterparts, potentially reflecting how multi-flow\n",
      "generation amplifies the number of handshake or handshake-like packets emitted by NetSSM.\n",
      "By contrast, Timestamp usage is extremely frequent for both real and synthetic traces, although\n",
      "single-flow real PCAPs exceed synthetic usage by a large margin. These differences underline\n",
      "that captured durations or concurrency levels can strongly influence aggregated option counts,\n",
      "making perfect numeric alignment a challenging goal. Rather than detracting from fidelity, these\n",
      "variants illustrate that NetSSM can produce either condensed or expanded views of typical network\n",
      "conditions, including advanced TCP features that manifest over extended sessions.\n",
      "Comparison with NetDiffusion Single-Flow. In addition to comparing NetSSM with real\n",
      "network captures, we also report results for NetDiffusion single-flow traces generated without\n",
      "its heuristic-based post-processing. NetDiffusion achieves 100% IP version correctness but has 0%\n",
      "(0/1000) correct three-way handshakes, suggesting that the raw generation does not properly model\n",
      "TCP’s initial SYN\n",
      "ACK progression. Similarly, the lack of sequence or acknowledgment\n",
      "progression in NetDiffusion data (0% for both SEQ and ACK progress) indicates minimal adherence\n",
      "to standard TCP ordering in the absence of further heuristics. Although 51.6% of NetDiffusion’s\n",
      "single-flow traces include a FIN, none of these are followed by a FIN-ACK, reinforcing an incomplete\n",
      "teardown or the model’s inability to produce such behavior. NetDiffusion traces also show no\n",
      "\n",
      "SYN-ACK\n",
      "\n",
      "→\n",
      "\n",
      "→\n",
      "\n",
      "15\n",
      "\n",
      "\fusage of RST states but exhibits a relatively high rate of conflicting flags (34.4%), which can create\n",
      "malformed segments, whereas NetSSM traces show far fewer conflicting flags (0.5%) in the single-\n",
      "flow case. Regarding TCP options, NetDiffusion single-flow traces incorporate certain features at\n",
      "high volumes (e.g., SAckOK or WScale), yet never re-introduce them mid-connection, unlike real\n",
      "traffic or NetSSM’s generation. Note that NetDiffusion traces do show zero occurrences of missing\n",
      "timestamps. However, this is largely because NetDiffusion relies on a post-generation sampling\n",
      "method to artificially add the timestamps into the synthetic packets. In sum, NetDiffusion’s intrinsic\n",
      "model, without correction rules, highlights partial or inaccurate TCP transitions that require manual\n",
      "fixes to achieve fully valid sessions.\n",
      "\n",
      "Our findings indicate that NetSSM synthesizes a wide range of valid TCP behaviors, captures\n",
      "standard handshake procedures in both single-flow and multi-flow contexts, and includes realistic\n",
      "anomalies such as partial teardown, reset events, and sometimes extraneous flags. Although certain\n",
      "discrepancies (e.g., more frequent conflicting flags in multi-flow, or greater FIN usage in single-flow)\n",
      "appear, these divergences often mirror real-world irregularities and can even enrich test scenarios\n",
      "for anomaly detection or intrusion prevention systems. The strong alignment on core handshake\n",
      "correctness and sequence tracking underscores NetSSM’s reliability in producing fundamentally\n",
      "valid TCP sessions. Furthermore, the inclusion of advanced TCP options (MSS, WScale, SACK) and\n",
      "timestamps—sometimes used in atypical ways—suggests that NetSSM is not merely generating\n",
      "“ideal” flows but is replicating many of the complexities and edge cases intrinsic to real network\n",
      "data. NetDiffusion, on the other hand, provides IP-correct single-flow data but does not reliably\n",
      "implement core TCP states—particularly around handshakes, sequence increments, and FIN-ACK\n",
      "completions—unless supplemented by subsequent heuristic-based post generation.\n",
      "\n",
      "5.3.3 Application Dynamics. We evaluate NetSSM’s ability to generate traces that capture the\n",
      "session dynamics of application-level streaming traffic. To do so, we infer the video download\n",
      "segments found in both the ground truth Netflix traces and the synthetic traces generated by\n",
      "NetSSM and compare the distributions of their quantities and sizes. We extract these segments from\n",
      "either data by identifying the IP addresses corresponding to Netflix CDN endpoints. Specifically, we\n",
      "examine each ground truth capture’s DNS traffic and collect the returned addresses corresponding\n",
      "to Netflix domains (i.e., containing nflxvideo, netflix, nflxso, nflxext). We use these addresses\n",
      "to filter both the ground truth and generated captures for video stream content, as our generated\n",
      "traces do not contain the DNS payload to perform the same procedure. Finally, for each flow between\n",
      "a Netflix address and the localhost in a trace, we track the number of segments downloaded and\n",
      "the size of each segment (not including header bytes). We then analyze the one-to-one differences\n",
      "in Netflix CDN sender behavior between synthetic and real-world traffic pairs. Unfortunately, it is\n",
      "not possible to compare the multi-flow traffic patterns captured by NetSSM with other generators.\n",
      "This is because no other generator can model the multi-flow sessions from which we can derive our\n",
      "analysis. As such, we attempt to provide a well-founded comparison against a randomly generated\n",
      "distribution that matches the distribution shape of our ground truth data. More details on this\n",
      "process are found in the following analysis, and more verbose results of our analysis with additional\n",
      "sample comparisons are in Appendix B.\n",
      "Downloaded Segment Sizes. We first compare the distributions for segment sizes across 1) all\n",
      "downloaded segments and 2) the average segment size per Netflix CDN sender in the ground\n",
      "truth and NetSSM-generated traces. We find that across different network scenarios, NetSSM’s\n",
      "synthetic data closely aligns with the ground truth traffic. Figure 3 shows applying kernel density\n",
      "estimation (KDE) to the average segment sizes per sender and log-transformed sizes of all raw\n",
      "segment sizes, and the empirical cumulative distribution function (ECDF) for raw segment sizes for\n",
      "either trace type, for two sample Netflix sessions with different data bit rates. We choose to apply\n",
      "\n",
      "16\n",
      "\n",
      "\f(a)\n",
      "\n",
      "(b)\n",
      "\n",
      "(c)\n",
      "\n",
      "(1)\n",
      "\n",
      "(2)\n",
      "\n",
      "Fig. 3. Distribution of downloaded segment sizes. (a) KDE plots for the average downloaded segment\n",
      "sizes per sender, (b) KDE plots for the log-transformed sizes of all downloaded segments, and (c) ECDF\n",
      "plots for all downloaded segments (non-log-transformed) displayed on a log scale, for two sampled pairs of\n",
      "generated and ground truth Netflix video stream traces. The ground truth traces in (1) and (2) have data bit\n",
      "rates of 554 and 1,366 kbps, respectively. NetSSM’s distributions overlap significantly with the real data.\n",
      "\n",
      ",\n",
      "\n",
      ",\n",
      "\n",
      "(\n",
      "\n",
      ")\n",
      "\n",
      ")\n",
      "\n",
      "(\n",
      "\n",
      ", and\n",
      "\n",
      "0.83, 0.71\n",
      "\n",
      "40.62, 39.08\n",
      "\n",
      "log transformation to the raw segment sizes to better visualize the two distributions, as both the\n",
      "ground truth and generated distributions of sizes are positively right-skewed with a higher volume\n",
      "of smaller segments (i.e., corresponding to session setup) than large segments (i.e., corresponding\n",
      "to actual video content download) present. We use log scale in the ECDF plots for the same reason.\n",
      "All KDE plots are created using a Gaussian kernel with (ground truth, generated) bandwidths of\n",
      "1.07, 0.99\n",
      "66.10, 55.85\n",
      "for sub-figures 1a, 1b, 2a, and 2b in Figure 3,\n",
      "(\n",
      "respectively, chosen using Scott’s rule of thumb in the scipy Python library [37, 46]. The (a) and\n",
      "(b) sub-figures well illustrate the similarity in downloaded segment sizes, where clear overlap exists\n",
      "between the segment sizes of the ground truth and synthetic data, even when considering instances\n",
      "of larger tail values. Similarly, in the ECDF plots, the generated traces overlap with the ground\n",
      "truth, as illustrated by similar magnitudes in the 25th, 50th, and 75th quartiles. In (1), the ground\n",
      "1829.50, 3465.00, 4195.25\n",
      "KB,\n",
      "truth and generated quartiles are\n",
      "and\n",
      "respectively. In (2), the ground truth and generated quartiles are\n",
      "and\n",
      "369.50, 3721.00, 14349.50\n",
      "KB, respectively. This provides further evidence that NetSSM generates\n",
      "(\n",
      "traces with similar size magnitudes across all segments, and with small and medium-sized segments\n",
      "are with similar absolute size, as compared to the ground truth.\n",
      "\n",
      "3048.75, 3465.00, 5792.00\n",
      ")\n",
      "(\n",
      "580.00, 4344.00, 41564.00\n",
      ")\n",
      "(\n",
      "\n",
      "(\n",
      "\n",
      "(\n",
      "\n",
      ")\n",
      "\n",
      ")\n",
      "\n",
      ")\n",
      "\n",
      ")\n",
      "\n",
      "We perform additional analysis using standard statistical measures, including the two-sample\n",
      "Kolmogorov-Smirnov (K-S) and Anderson-Darling tests, Kullback-Leibler (KL) divergence, and the\n",
      "earth mover’s distance (EMD). The “Avg. Size” and “Raw Size” evaluations in Table 5 show the\n",
      "results of this analysis for downloaded segment sizes. We provide a basis for comparison against a\n",
      "positively right-skewed distribution of random values, to approximate the ground truth distribution\n",
      "shape. The values are randomly selected between the minimum and maximum values for each\n",
      "evaluation (i.e., average size, raw size, quantity) per ground truth trace. In the Mean Δ and Median\n",
      "Δ statistical measures, Δ ≔\n",
      "1, 100\n",
      ".\n",
      "]\n",
      "To contrast, Std. Dev. Δ ≔ 𝑚𝑒𝑑𝑖𝑎𝑛\n",
      ". We\n",
      ") −\n",
      "observe that as an aggregate, across all traces regardless of differing collection device type and\n",
      "\n",
      "𝑚𝑒𝑑𝑖𝑎𝑛𝐺𝑇𝑖 (\n",
      "|\n",
      "𝜎𝐺𝑇𝑖 (\n",
      "(|\n",
      "\n",
      "𝑅𝑎𝑛𝑑𝑜𝑚𝑖 (\n",
      "eval\n",
      "\n",
      "𝑚𝑒𝑑𝑖𝑎𝑛𝑁 𝑒𝑡𝑆𝑆𝑀\n",
      "\n",
      "𝑅𝑎𝑛𝑑𝑜𝑚𝑖 (\n",
      "\n",
      ", where 𝑖\n",
      "\n",
      "∈ [\n",
      "1, 100\n",
      "\n",
      "𝜎𝑁 𝑒𝑡𝑆𝑆𝑀\n",
      "\n",
      "where 𝑖\n",
      "\n",
      "eval\n",
      "\n",
      "eval\n",
      "\n",
      "eval\n",
      "\n",
      ") −\n",
      "\n",
      "∈ [\n",
      "\n",
      ")|)\n",
      "\n",
      ")|\n",
      "\n",
      "]\n",
      "\n",
      "/\n",
      "\n",
      "/\n",
      "\n",
      "17\n",
      "\n",
      "−2000200400600Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.006DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.00.10.20.3DensityGroundTruthGenerated102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.−1000100200300Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.0060.008DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.000.050.100.15DensityGroundTruthGenerated102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.\fTable 5. Statistical comparison of real/synthetic distributions for segment size and count. Compar-\n",
      "ison of raw and average size, and segment count between ground-truth and synthetic traces. NetSSM’s\n",
      "distributions align reasonably with those of the real data.\n",
      "\n",
      "Comp. w/\n",
      "Ground\n",
      "Truth\n",
      "\n",
      "Evaluation\n",
      "\n",
      "NetSSM Avg. Size\n",
      "Random Avg. Size\n",
      "NetSSM Raw Size\n",
      "Random Raw Size\n",
      "NetSSM # Segments\n",
      "Random # Segments\n",
      "\n",
      "Statistical Measures\n",
      "\n",
      "K–S Test\n",
      "\n",
      "Anderson-Darling Test KL Divergence\n",
      "\n",
      "EMD\n",
      "\n",
      "Mean Δ Median Δ Std. Dev. Δ Stat.\n",
      "\n",
      "4.15\n",
      "5.40\n",
      "2.56\n",
      "4.43\n",
      "43.78\n",
      "30.81\n",
      "\n",
      "1.28\n",
      "3.86\n",
      "1.28\n",
      "3.58\n",
      "1.00\n",
      "13.15\n",
      "\n",
      "79.08\n",
      "103.27\n",
      "209.80\n",
      "256.95\n",
      "15.71\n",
      "6.25\n",
      "\n",
      "0.22\n",
      "1.00\n",
      "0.21\n",
      "0.80\n",
      "0.17\n",
      "0.42\n",
      "\n",
      "↓\n",
      "\n",
      "↑\n",
      "\n",
      "p-value\n",
      "\n",
      "0.82\n",
      "0.00\n",
      "0.03*\n",
      "0.00\n",
      "0.95\n",
      "0.26\n",
      "\n",
      "Stat.\n",
      "\n",
      "↓\n",
      "0.29\n",
      "11.90\n",
      "6.86\n",
      "62.74\n",
      "0.41\n",
      "2.08\n",
      "\n",
      "↑\n",
      "\n",
      "p-value\n",
      "\n",
      "0.73\n",
      "0.00\n",
      "0.01†\n",
      "0.00\n",
      "0.76\n",
      "0.35\n",
      "\n",
      "Stat. (nats)\n",
      "\n",
      "2.67\n",
      "4.62\n",
      "1.14\n",
      "2.86\n",
      "2.97\n",
      "6.83\n",
      "\n",
      "↓\n",
      "\n",
      "Dist.\n",
      "\n",
      "↓\n",
      "30.75\n",
      "44.50\n",
      "72.94\n",
      "88.74\n",
      "8.04\n",
      "15.72\n",
      "\n",
      "Values for the statistic, p-value, and distance are the median values.\n",
      "\n",
      "*Mean value is 0.19, †Mean value is 0.13.\n",
      "\n",
      "link speed, that NetSSM’s synthetic traces have lower deltas for all three statistical measures for\n",
      "both raw segment size and average segment size per CDN sender. To continue, the results for\n",
      "the statistical tests (K-S, Anderson-Darling) and information theory and distance measures (KL\n",
      "divergence, EMD) further separate NetSSM’s output from the random distribution.\n",
      "\n",
      "The two-sample K-S and Anderson-Darling tests evaluate the likelihood that data come from\n",
      "the same underlying distribution, calculating a statistic representing the largest distance found\n",
      "between ECDFs for either data (with the Anderson-Darling test giving additional weighting to\n",
      "differences in the distribution of tail values), and a p-value detailing the chance of observing a test\n",
      "statistic as extreme as the statistic if the null hypothesis that the two samples are from the same\n",
      "distribution is true. For both tests, across all evaluations, we choose a confidence interval of 0.95\n",
      "wherein we accept the null hypothesis if the p-value is greater than 0.05 and reject it otherwise.\n",
      "We find that for either test and evaluation, the median statistic value for the random distribution is\n",
      "significantly higher than for the generated traces. Specifically, in the K-S tests, the values are exactly\n",
      "and close to (0.80), the maximum possible value of 1.0. The Anderson-Darling tests’ statistics are\n",
      "similarly near an order of magnitude (or greater) larger than those of the generated. Examining the\n",
      "tests’ p-values, the null hypothesis is accepted in the average size evaluation for both tests of the\n",
      "synthetic trace (p-values 0.82 and 0.73), but rejected in either test for the random distribution with\n",
      "values of 0.00. In the raw segment size evaluation, the median p-values are near zero or zero for\n",
      "either test in our generated data and the random distribution. However, we observe mean p-values\n",
      "of 0.19 and 0.13 that could plausibly accept the null hypothesis in our generated traces for both\n",
      "tests. In contrast, the mean p-values for the random distributions remain zero for both tests.\n",
      "\n",
      "Finally, the KL divergence and EMD compare the similarity or dissimilarity between two proba-\n",
      "bility distributions, where the KL divergence is the amount of information lost when using one\n",
      "distribution to approximate the other (given that the set of possible outcomes is consistent be-\n",
      "tween distributions), and EMD is the minimum cost to transform one distribution to the other. We\n",
      "find across both size evaluations and measures that the generated traces can be more efficiently\n",
      "transformed to the ground truth than the random distribution.\n",
      "Downloaded Segment Count. We also evaluate the number of segments downloaded both in\n",
      "NetSSM’s synthetic traces and in the ground truth. Similar to evaluation of segments’ sizes, we\n",
      "find that NetSSM produces data that closely aligns with the ground truth traffic. Figure 4 shows\n",
      "the KDE plots for the log-transformed number of downloaded segments, and the ECDF plots for\n",
      "the raw number of downloaded segments, shown on a log scale. Specifically, the ground truth\n",
      "traces depicted by this figure are the same traces whose segment sizes are visualized in Figure 3,\n",
      "captured at two different data bit rates. We choose to apply log-transformation to, and show\n",
      "the number of segments in log scale for better analysis of overall patterns and visualization, as\n",
      "similar to downloaded segment sizes, the distribution for number of segments downloaded is\n",
      "\n",
      "18\n",
      "\n",
      "\f(1)\n",
      "\n",
      "(2)\n",
      "\n",
      "Fig. 4. Distribution of downloaded segment count. KDE plots for the log-transformed number of down-\n",
      "loaded segments sent per sender, and ECDF plots for the number of downloaded segments sent per sender\n",
      "(non-log-transformed) displayed on a log scale, for two sampled pairs of generated and ground truth Netflix\n",
      "video stream traces. The ground truth traces in (1) and (2) have to data bit rates of 554 and 1,366 kbps,\n",
      "respectively. NetSSM’s distributions overlap significantly with the real data.\n",
      "\n",
      "positively right-skewed. There again exists clear overlap in the KDE plots for number of segments\n",
      "downloaded between the ground truth and synthetic data, though it appears NetSSM’s traces\n",
      "may not completely capture the tail end cases of higher volume senders. The quartile values\n",
      "from the ECDFs further support the overlap, with only small deltas between the ground truth\n",
      "4.50, 10.00, 12.00\n",
      "and generated. In scenario (1), the ground truth and generated quartiles are\n",
      ")\n",
      "segments downloaded, respectively. Similarly, in scenario (2), the ground\n",
      "and\n",
      "segments\n",
      "truth quartiles are\n",
      "downloaded, respectively.\n",
      "\n",
      ")\n",
      "7.00, 10.00, 12.75\n",
      ")\n",
      "\n",
      ", and the generated quartiles are\n",
      "\n",
      "5.75, 9.50, 11.75\n",
      ")\n",
      "\n",
      "3.25, 8.00, 10.75\n",
      "\n",
      "(\n",
      "\n",
      "(\n",
      "\n",
      "(\n",
      "\n",
      "(\n",
      "\n",
      "We next examine the “# Segments” evaluation in Table 5, compared against the same positively\n",
      "right-skewed distribution of random values, and same definitions of Δ for Mean Δ, Median Δ and\n",
      "Std. Dev. Δ respectively, as described in our analysis of download segment sizes. We observe the\n",
      "Median Δ of number of downloaded segments in the generated trace aligns more closely than the\n",
      "random distribution with the ground truth. However, the Mean Δ and Std. Dev. Δ of number of\n",
      "downloaded segments is lower when comparing the ground truth to the random distribution. This\n",
      "can be attributed to the relatively narrow range of values to be randomly selected from alongside\n",
      "the low number of CDN senders to emulate quantity of number of downloaded segments for.\n",
      "\n",
      "In the remaining statistical hypothesis tests and measures of similarity, we observe that NetSSM\n",
      "produces traces that appear to closely mimic, but not copy the ground truth traces. Using the\n",
      "same null hypothesis (two samples are from the same distribution) and 0.05 p-value threshold as\n",
      "described for segment sizes, the median p-values for both the K-S and Anderson-Darling tests are\n",
      "0.95 and 0.76 respectively (as compared to 0.26 and 0.35 from the random distribution), indicating\n",
      "strong evidence for accepting the null hypothesis that the generated and ground truth traces are\n",
      "sampled from the same underlying distribution. Similarly, the median KL divergence and EMD\n",
      "indicate that distribution for the number of segments extracted from generated traces can be more\n",
      "efficiently transformed to match that of the ground truth, than the random distribution.\n",
      "\n",
      "We find that the synthetic traces generated by NetSSM closely mimic the application dynamics\n",
      "of real-world video streaming data. NetSSM captures both the raw sizes of downloaded segments,\n",
      "and number of segments sent per CDN sender at fine-granularity, and this capability persists\n",
      "across various configurations and conditions (e.g., data bit rate and corresponding bandwidth). This\n",
      "supports our belief that NetSSM is able to more comprehensively model interactions not only\n",
      "between packets, but between multiple-flows.\n",
      "\n",
      "6 DISCUSSION, LIMITATIONS, AND FUTURE WORK\n",
      "\n",
      "Improving NetSSM. Synthetic traces generated by NetSSM do not currently include the temporal\n",
      "interarrival times (IATs) between packets in a capture. This quality is an important strength of\n",
      "\n",
      "19\n",
      "\n",
      "024No.ofSegments(LogTransformed)0.00.10.20.30.40.5DensityGroundTruthGenerated101No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.−20246No.ofSegments(LogTransformed)0.00.10.20.30.4DensityGroundTruthGenerated100101102No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.\fPCAPs that allows one to extract various temporal-dependent flow and packet-level statistics\n",
      "commonly preferred for use in downstream analysis and ML-based tasks. Generating both raw\n",
      "packet data and their corresponding IATs is a difficult task, as these values are not contained in\n",
      "packets’ contents but are assigned at capture time by packet capturing tools at the OS level. Further,\n",
      "while generating byte values produces discrete values, IATs are continuous data. An improvement on\n",
      "NetSSM should describe an architecture that produces these two data in parallel while maintaining\n",
      "the workload dependencies induced by either onto the other.\n",
      "Improving Metrics of Synthetic Data Quality. Prior work measured the quality of their synthetic\n",
      "traces by (1) calculating the statistical similarity between their generated data and ground truth\n",
      "real traffic and (2) evaluating the performance of downstream ML-for-networking models trained\n",
      "or fine-tuned on synthetic data. In our work, we present an analysis of the semantic similarity of\n",
      "NetSSM-generated traces via a case study using a model trained on Netflix video streaming traffic.\n",
      "Through this, we aimed to provide an additional perspective on what “good” synthetic traffic may\n",
      "look like by closely mimicking – but not copying – the protocol/session compliance and sending\n",
      "behavior of session nodes. However, additional case studies of different networked communication\n",
      "workloads could make this evaluation more robust and generalizable.\n",
      "Bridging semantic similarity and downstream applications Our work evaluates semantic\n",
      "similarity using metrics such as protocol/session compliance and sending behaviors. However,\n",
      "similar to how we verified the impact of statistical similarity on classification-based downstream\n",
      "tasks, future work could focus on translating semantic similarity into measurable improvements in\n",
      "downstream applications. For example, tasks such as intrusion detection and anomaly detection\n",
      "could directly benefit from enhanced semantic fidelity, as it ensures realistic and coherent traffic\n",
      "interactions. Evaluating how semantic similarity impacts these tasks would provide deeper insights\n",
      "into its practical utility and guide improvements in synthetic traffic generation.\n",
      "\n",
      "7 CONCLUSION\n",
      "\n",
      "×\n",
      "\n",
      "and 78\n",
      "\n",
      "In this paper, we presented NetSSM, a novel Mamba SSM-based raw packet generator. To our\n",
      "knowledge, NetSSM is the first network data generator capable of producing PCAPs for sessions\n",
      "comprised of multiple interleaved flows. NetSSM’s sequential, stateful architecture enables it\n",
      "to learn from, and produce sessions 8\n",
      "longer, respectively, than the current state-of-\n",
      "×\n",
      "the-art transformer-based raw packet generator. This in turn, allows it to capture key flow-state-\n",
      "dependent session events that only manifest after substantial setup. NetSSM outperforms all\n",
      "previous generators regardless of output format (i.e., summary statistics/traffic attributes of network\n",
      "data, or similar raw PCAPs) in measures of statistical similarity and as measured by the performance\n",
      "of downstream ML-for-networking models trained on NetSSM data. We additionally evaluate\n",
      "NetSSM’s traces on a new metric of semantic similarity, which aims to better reason about the\n",
      "empirical, practical similarities between NetSSM’s synthetic output and real-world network data.\n",
      "First, we find that NetSSM’s generated traces largely adhere to valid TCP behaviors required to\n",
      "reproduce complex patterns in real traffic data. Second, we find that NetSSM can faithfully capture\n",
      "complex application dynamics of multi-flow networked communication, and does so across varying\n",
      "network conditions. We are hopeful that future research towards producing synthetic network data\n",
      "will continue to evaluate both the statistical and semantic similarities of generated traces to better\n",
      "test the usefulness of this data, whether via further developments to NetSSM or other methods.\n",
      "\n",
      "20\n",
      "\n",
      "\fREFERENCES\n",
      "\n",
      "[1] Sebastian Abt and Harald Baier. 2014. Are we missing labels? A study of the availability of ground-truth in network\n",
      "security research. In 2014 third international workshop on building analysis datasets and gathering experience returns for\n",
      "security (badgers). IEEE, 40–55.\n",
      "\n",
      "[2] Fred Baker, Bill Foster, and Chip Sharp. 2004. Cisco architecture for lawful intercept in IP networks. Internet Engineering\n",
      "\n",
      "Task Force, RFC 3924 (2004).\n",
      "\n",
      "[3] Alessio Botta, Alberto Dainotti, and Antonio Pescapé. 2012. A tool for the generation of realistic network workload\n",
      "\n",
      "for emerging networking scenarios. Computer Networks 56, 15 (2012), 3531–3547.\n",
      "\n",
      "[4] Francesco Bronzino, Paul Schmitt, Sara Ayoubi, Guilherme Martins, Renata Teixeira, and Nick Feamster. 2019. Inferring\n",
      "streaming video quality from encrypted traffic: Practical models and deployment experience. Proceedings of the ACM\n",
      "on Measurement and Analysis of Computing Systems 3, 3 (2019), 1–25.\n",
      "\n",
      "[5] Tobias Bühler, Roland Schmid, Sandro Lutz, and Laurent Vanbever. 2022. Generating representative, live network\n",
      "traffic out of millions of code repositories. In Proceedings of the 21st ACM Workshop on Hot Topics in Networks. 1–7.\n",
      "[6] Lelio Campanile, Marco Gribaudo, Mauro Iacono, Fiammetta Marulli, and Michele Mastroianni. 2020. Computer\n",
      "\n",
      "network simulation with ns-3: A systematic literature review. Electronics 9, 2 (2020), 272.\n",
      "\n",
      "[7] Andrew Chu, Xi Jiang, Shinan Liu, Arjun Bhagoji, Francesco Bronzino, Paul Schmitt, and Nick Feamster. 2024. Feasibility\n",
      "of state space models for network traffic generation. In Proceedings of the 2024 SIGCOMM Workshop on Networks for AI\n",
      "Computing. 9–17.\n",
      "\n",
      "[8] ciscotrex2023 2024. The CISCO TRex Tool. https://trex-tgn.cisco.com/. [Online; accessed 31-May-2024].\n",
      "[9] Tri Dao and Albert Gu. 2024. Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured\n",
      "State Space Duality. In Proceedings of the 41st International Conference on Machine Learning (Proceedings of Machine\n",
      "Learning Research, Vol. 235), Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan\n",
      "Scarlett, and Felix Berkenkamp (Eds.). PMLR, 10041–10071. https://proceedings.mlr.press/v235/dao24a.html\n",
      "\n",
      "[10] François De Keersmaeker, Yinan Cao, Gorby Kabasele Ndonda, and Ramin Sadre. 2023. A Survey of Public IoT Datasets\n",
      "\n",
      "for Network Security Research. IEEE Communications Surveys & Tutorials (2023).\n",
      "[11] Let’s Encrypt. 2024. Let’s Encrypt Stats. https://letsencrypt.org/stats/ Accessed: 2024.\n",
      "[12] Sebastián García, Karel Hynek, Dmtrii Vekshin, Tomáš Čejka, and Armin Wasicek. 2021. Large Scale Measurement on\n",
      "\n",
      "the Adoption of Encrypted DNS. arXiv:2107.04436 [cs.CR] https://arxiv.org/abs/2107.04436\n",
      "\n",
      "[13] Albert Gu and Tri Dao. 2023. Mamba: Linear-time sequence modeling with selective state spaces. arXiv preprint\n",
      "\n",
      "arXiv:2312.00752 (2023).\n",
      "\n",
      "[14] Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher R é. 2020. Hippo: Recurrent memory with optimal\n",
      "\n",
      "polynomial projections. Advances in neural information processing systems 33 (2020), 1474–1487.\n",
      "\n",
      "[15] Albert Gu, Karan Goel, and Christopher Ré. 2021. Efficiently modeling long sequences with structured state spaces.\n",
      "\n",
      "arXiv preprint arXiv:2111.00396 (2021).\n",
      "\n",
      "[16] Thomas R Henderson, Mathieu Lacage, George F Riley, Craig Dowell, and Joseph Kopena. 2008. Network simulations\n",
      "\n",
      "with the ns-3 simulator. SIGCOMM demonstration 14, 14 (2008), 527.\n",
      "\n",
      "[17] Paul E. Hoffman and Patrick McManus. 2018. DNS Queries over HTTPS (DoH). RFC 8484. https://doi.org/10.17487/\n",
      "\n",
      "RFC8484\n",
      "\n",
      "[18] Jordan Holland, Paul Schmitt, Nick Feamster, and Prateek Mittal. 2021. New Directions in Automated Traffic Analysis\n",
      "(CCS ’21). Association for Computing Machinery, New York, NY, USA, 3366–3383. https://doi.org/10.1145/3460120.\n",
      "3484758\n",
      "\n",
      "[19] Zi Hu, Liang Zhu, John Heidemann, Allison Mankin, Duane Wessels, and Paul E. Hoffman. 2016. Specification for DNS\n",
      "\n",
      "over Transport Layer Security (TLS). RFC 7858. https://doi.org/10.17487/RFC7858\n",
      "\n",
      "[20] Xi Jiang and Noah Apthorpe. 2021. Automating Internet of Things network traffic collection with robotic arm\n",
      "\n",
      "interactions. arXiv preprint arXiv:2110.00060 (2021).\n",
      "\n",
      "[21] Xi Jiang, Shinan Liu, Aaron Gember-Jacobson, Arjun Nitin Bhagoji, Paul Schmitt, Francesco Bronzino, and Nick Feam-\n",
      "ster. 2024. NetDiffusion: Network Data Augmentation Through Protocol-Constrained Traffic Generation. Proceedings\n",
      "of the ACM on Measurement and Analysis of Computing Systems 8, 1 (2024), 1–32.\n",
      "\n",
      "[22] Xi Jiang, Shinan Liu, Saloua Naama, Francesco Bronzino, Paul Schmitt, and Nick Feamster. 2023. AC-DC: Adaptive\n",
      "\n",
      "Ensemble Classification for Network Traffic Identification. arXiv preprint arXiv:2302.11718 (2023).\n",
      "[23] Rudolph Emil Kalman. 1960. A new approach to linear filtering and prediction problems. (1960).\n",
      "[24] Mathieu Lacage and Thomas R Henderson. 2006. Yet another network simulator. In Proceedings of the 2006 Workshop\n",
      "\n",
      "on ns-3. 12–es.\n",
      "\n",
      "[25] Jianfeng Li, Hao Zhou, Shuohan Wu, Xiapu Luo, Ting Wang, Xian Zhan, and Xiaobo Ma. 2022.\n",
      "\n",
      "Fine-\n",
      "android app fingerprinting. In 31st USENIX Security Symposium (USENIX Security 22). 1579–\n",
      "\n",
      "FOAP\n",
      "\n",
      "{\n",
      "\n",
      "{\n",
      "\n",
      "}\n",
      "\n",
      ":\n",
      "\n",
      "Grained\n",
      "1596.\n",
      "\n",
      "} {\n",
      "\n",
      "Open-World\n",
      "\n",
      "}\n",
      "\n",
      "21\n",
      "\n",
      "\f[26] Xinjie Lin, Gang Xiong, Gaopeng Gou, Zhen Li, Junzheng Shi, and Jing Yu. 2022. ET-BERT: A Contextualized Datagram\n",
      "Representation with Pre-training Transformers for Encrypted Traffic Classification. In Proceedings of the ACM Web\n",
      "Conference 2022 (WWW ’22). ACM. https://doi.org/10.1145/3485447.3512217\n",
      "\n",
      "[27] Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar. 2020. Using gans for sharing networked time series\n",
      "data: Challenges, initial promise, and open questions. In Proceedings of the ACM Internet Measurement Conference.\n",
      "464–483.\n",
      "\n",
      "[28] Shinan Liu, Francesco Bronzino, Paul Schmitt, Arjun Nitin Bhagoji, Nick Feamster, Hector Garcia Crespo, Timothy\n",
      "Coyle, and Brian Ward. 2023. LEAF: Navigating Concept Drift in Cellular Networks. Proceedings of the ACM on\n",
      "Networking 1, CoNEXT2 (2023), 1–24.\n",
      "\n",
      "[29] Shinan Liu, Tarun Mangla, Ted Shaowang, Jinjin Zhao, John Paparrizos, Sanjay Krishnan, and Nick Feamster. 2023.\n",
      "Amir: Active multimodal interaction recognition from video and network traffic in connected environments. Proceedings\n",
      "of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 7, 1 (2023), 1–26.\n",
      "\n",
      "[30] Shinan Liu, Ted Shaowang, Gerry Wan, Jeewon Chae, Jonatas Marques, Sanjay Krishnan, and Nick Feamster. 2024.\n",
      "ServeFlow: A Fast-Slow Model Architecture for Network Traffic Analysis. arXiv preprint arXiv:2402.03694 (2024).\n",
      "[31] Chaoyi Lu, Baojun Liu, Zhou Li, Shuang Hao, Haixin Duan, Mingming Zhang, Chunying Leng, Ying Liu, Zaifeng\n",
      "Zhang, and Jianping Wu. 2019. An end-to-end, large-scale measurement of dns-over-encryption: How far have we\n",
      "come?. In Proceedings of the Internet Measurement Conference. 22–35.\n",
      "\n",
      "[32] Kyle MacMillan, Tarun Mangla, James Saxon, and Nick Feamster. 2021. Measuring the performance and network\n",
      "utilization of popular video conferencing applications. In Proceedings of the 21st ACM Internet Measurement Conference.\n",
      "229–244.\n",
      "\n",
      "[33] Xuying Meng, Chungang Lin, Yequan Wang, and Yujun Zhang. 2023. Netgpt: Generative pretrained transformer for\n",
      "\n",
      "network traffic. arXiv preprint arXiv:2304.09513 (2023).\n",
      "\n",
      "[34] Anthony Moi and Nicolas Patry. 2023. HuggingFace’s Tokenizers. https://github.com/huggingface/tokenizers\n",
      "[35] Vern Paxson. 1999. Bro: a system for detecting network intruders in real-time. Computer networks 31, 23-24 (1999),\n",
      "\n",
      "2435–2463.\n",
      "\n",
      "[36] Jian Qu, Xiaobo Ma, and Jianfeng Li. 2024. TrafficGPT: Breaking the Token Barrier for Efficient Long Traffic Analysis\n",
      "\n",
      "and Generation. arXiv preprint arXiv:2403.05822 (2024).\n",
      "\n",
      "[37] David W Scott. 2015. Multivariate density estimation: theory, practice, and visualization. John Wiley & Sons.\n",
      "[38] Ranya Sharma, Nick Feamster, and Austin Hounsel. 2022. Measuring the Availability and Response Times of Public\n",
      "\n",
      "Encrypted DNS Resolvers. arXiv:2208.04999 [cs.CR] https://arxiv.org/abs/2208.04999\n",
      "\n",
      "[39] Taveesh Sharma, Tarun Mangla, Arpit Gupta, Junchen Jiang, and Nick Feamster. 2023. Estimating WebRTC Video\n",
      "QoE Metrics Without Using Application Headers. In Proceedings of the 2023 ACM on Internet Measurement Conference\n",
      "(Montreal QC, Canada) (IMC ’23). Association for Computing Machinery, New York, NY, USA, 485–500. https:\n",
      "//doi.org/10.1145/3618257.3624828\n",
      "\n",
      "[40] shramos. 2019. shramos/pcap-splitter. https://github.com/shramos/pcap-splitter.\n",
      "[41] Pallavi Singhal, Rajeev Mathur, and Himani Vyas. 2013. State of the Art Review of Network Traffic Classification based\n",
      "\n",
      "on Machine Learning Approach. International Journal of Computer Applications 975 (2013), 8887.\n",
      "\n",
      "[42] Iraj Sodagar. 2011. The MPEG-DASH Standard for Multimedia Streaming Over the Internet. IEEE MultiMedia 18, 4\n",
      "\n",
      "(2011), 62–67. https://doi.org/10.1109/MMUL.2011.71\n",
      "\n",
      "[43] Robin Sommer and Vern Paxson. 2010. Outside the Closed World: On Using Machine Learning for Network Intrusion\n",
      "\n",
      "Detection. In 2010 IEEE Symposium on Security and Privacy. 305–316. https://doi.org/10.1109/SP.2010.25\n",
      "\n",
      "[44] Robin Sommer and Vern Paxson. 2010. Outside the closed world: On using machine learning for network intrusion\n",
      "\n",
      "detection. In 2010 IEEE symposium on security and privacy. IEEE, 305–316.\n",
      "\n",
      "[45] Matthew Swann, Joseph Rose, Gueltoum Bendiab, Stavros Shiaeles, and Nick Savage. 2021. Tools for Network Traffic\n",
      "\n",
      "Generation–A Quantitative Comparison. arXiv preprint arXiv:2109.02760 (2021).\n",
      "\n",
      "[46] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski,\n",
      "Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod\n",
      "Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, İlhan Polat, Yu\n",
      "Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero,\n",
      "Charles R. Harris, Anne M. Archibald, Antô nio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0\n",
      "Contributors. 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods 17 (2020),\n",
      "261–272. https://doi.org/10.1038/s41592-019-0686-2\n",
      "\n",
      "[47] Aaron Voelker, Ivana Kajić, and Chris Eliasmith. 2019. Legendre memory units: Continuous-time representation in\n",
      "\n",
      "recurrent neural networks. Advances in neural information processing systems 32 (2019).\n",
      "\n",
      "[48] Gerry Wan, Shinan Liu, Francesco Bronzino, Nick Feamster, and Zakir Durumeric. 2024. CATO: End-to-End Optimiza-\n",
      "\n",
      "tion of ML-Based Traffic Analysis Pipelines. arXiv preprint arXiv:2402.06099 (2024).\n",
      "\n",
      "22\n",
      "\n",
      "\f[49] Yucheng Yin, Zinan Lin, Minhao Jin, Giulia Fanti, and Vyas Sekar. 2022. Practical gan-based synthetic ip header trace\n",
      "\n",
      "generation using netshare. In Proceedings of the ACM SIGCOMM 2022 Conference. 458–472.\n",
      "\n",
      "[50] Shiyuan Zhang, Tong Li, Depeng Jin, and Yong Li. 2024. NetDiff: A Service-Guided Hierarchical Diffusion Model for\n",
      "\n",
      "Network Flow Trace Generation. Proceedings of the ACM on Networking 2, CoNEXT3 (2024), 1–21.\n",
      "\n",
      "23\n",
      "\n",
      "\fA COMPREHENSIVE RESULTS ON DOWNSTREAM UTILIZATION\n",
      "\n",
      "Fig. 5. Comparative ML performance across different model choices with mixed training data proportions.\n",
      "\n",
      "Fig. 6. Comparative ML performance across different model choices with mixed training data proportions\n",
      "(Skipping first packet for NetSSM-generated traces).\n",
      "\n",
      "24\n",
      "\n",
      "0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0AccuracyApp Level; Tested on Real Data0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0Service Type Level; Tested on Real Data0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0App Level; Tested on Syn DataRF, NETSSM (base)DT, NETSSM (base)SVM, NETSSM (base)RF, NETSSM (fine-tuned)DT, NETSSM (fine-tuned)SVM, NETSSM (fine-tuned)0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0AccuracyService Type Level; Tested on Syn DataRF, NetDiffusionDT, NetDiffusionSVM, NetDiffusionRF, NetShareDT, NetShareSVM, NetShare0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0AccuracyApp Level; Tested on Real Data0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0Service Type Level; Tested on Real Data0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0App Level; Tested on Syn DataNo Seed UsedRF, NETSSM (base)DT, NETSSM (base)SVM, NETSSM (base)RF, NETSSM (fine-tuned)DT, NETSSM (fine-tuned)SVM, NETSSM (fine-tuned)0.00.20.40.60.81.0Mixing Rate0.00.20.40.60.81.0AccuracyService Type Level; Tested on Syn DataRF, NetDiffusionDT, NetDiffusionSVM, NetDiffusionRF, NetShareDT, NetShareSVM, NetShare\fB ADDITIONAL VIDEO STREAMING SEGMENT RESULTS\n",
      "\n",
      "The scenarios shown in all figures below have the following ground truth data bit rates: (1) 554\n",
      "\n",
      "kbps, (2) 1,366 kbps, (3) 2,726 kbps, (4) 2,460 kbps, (5) 1,361 kbps, and (6) 1,450 kbps.\n",
      "\n",
      "B.1 Downloaded Segment Sizes\n",
      "\n",
      "(a)\n",
      "\n",
      "(b)\n",
      "\n",
      "(c)\n",
      "\n",
      "(d)\n",
      "\n",
      "(1)\n",
      "\n",
      "(2)\n",
      "\n",
      "(3)\n",
      "\n",
      "(4)\n",
      "\n",
      "(5)\n",
      "\n",
      "(6)\n",
      "\n",
      "Fig. 7. KDE plots for downloaded segment sizes.\n",
      "\n",
      "Figure 7 shows additional visualizations for both the average downloaded segment sizes and raw\n",
      "downloaded segments sizes. Specifically: (a) KDE plots for the average downloaded segment sizes\n",
      "per sender, (b) KDE plots for the log-transformed average downloaded segment sizes per sender, (c)\n",
      "KDE plots for the sizes of all downloaded segments and (d) KDE plots for the log-transformed sizes\n",
      "of all downloaded segments.\n",
      "\n",
      "25\n",
      "\n",
      "−2000200400600Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.006DensityGroundTruthGenerated−2.50.02.55.07.5Avg.Seg.SizeperCDNSender(KB,LogTrans.)0.000.050.100.150.200.25DensityGroundTruthGenerated0500100015002000RawSegmentSize(KB)0.0000.0020.0040.0060.008DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.00.10.20.3DensityGroundTruthGenerated−1000100200300Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.0060.008DensityGroundTruthGenerated−2.50.02.55.07.5Avg.Seg.SizeperCDNSender(KB,LogTrans.)0.000.050.100.150.200.25DensityGroundTruthGenerated05001000RawSegmentSize(KB)0.0000.0020.0040.0060.0080.010DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.000.050.100.15DensityGroundTruthGenerated−2000200400600800Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.0060.0080.010DensityGroundTruthGenerated−2.50.02.55.07.510.0Avg.Seg.SizeperCDNSender(KB,LogTrans.)0.000.050.100.150.20DensityGroundTruthGenerated0500100015002000RawSegmentSize(KB)0.0000.0050.0100.0150.020DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.000.050.100.15DensityGroundTruthGenerated−1000100200300Avg.SegmentSizeperCDNSender(KB)0.00000.00250.00500.00750.01000.0125DensityGroundTruthGenerated−2.50.02.55.07.5Avg.Seg.SizeperCDNSender(KB,LogTrans.)0.000.050.100.150.20DensityGroundTruthGenerated050010001500RawSegmentSize(KB)0.00000.00250.00500.00750.01000.0125DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.00.10.20.30.4DensityGroundTruthGenerated−2000200400600Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.006DensityGroundTruthGenerated−2.50.02.55.07.510.0Avg.Seg.SizeperCDNSender(KB,LogTrans.)0.000.050.100.150.20DensityGroundTruthGenerated010002000RawSegmentSize(KB)0.0000.0020.0040.006DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.000.050.100.150.200.25DensityGroundTruthGenerated−1000100200300Avg.SegmentSizeperCDNSender(KB)0.0000.0020.0040.0060.0080.010DensityGroundTruthGenerated−202468Avg.Seg.SizeperCDNSender(KB,LogTrans.)0.00.10.20.3DensityGroundTruthGenerated−25002505007501000RawSegmentSize(KB)0.0000.0020.0040.006DensityGroundTruthGenerated−50510RawSegmentSize(KB,LogTransformed)0.000.050.100.15DensityGroundTruthGenerated\f(1)\n",
      "\n",
      "(4)\n",
      "\n",
      "(2)\n",
      "\n",
      "(5)\n",
      "\n",
      "(3)\n",
      "\n",
      "(6)\n",
      "\n",
      "Fig. 8. ECDF plots for all downloaded segments, across different scenarios.\n",
      "\n",
      "Figure 8 shows additional visualizations for the ECDFs of downloaded segment sizes for all\n",
      "\n",
      "downloaded segments.\n",
      "\n",
      "26\n",
      "\n",
      "102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.102103104105106RawSegmentSize(LogScale)0.00.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.\fB.2 Number of Downloaded Segments\n",
      "\n",
      "Figure 9 shows additional visualizations for the number of downloaded segments. Specifically:\n",
      "(a) KDE plots for the raw number of downloaded segments per CDN and (b) KDE plots for the\n",
      "log-transformed raw number of downloaded segments sizes per CDN sender.\n",
      "\n",
      "Figure 10 shows additional visualizations for the ECDFs of the number of downloaded segments.\n",
      "\n",
      "27\n",
      "\n",
      "\f(a)\n",
      "\n",
      "(b)\n",
      "\n",
      "(1)\n",
      "\n",
      "(2)\n",
      "\n",
      "(3)\n",
      "\n",
      "(4)\n",
      "\n",
      "(5)\n",
      "\n",
      "(6)\n",
      "\n",
      "Fig. 9. KDE plots for number of downloaded segments.\n",
      "\n",
      "28\n",
      "\n",
      "−20020406080NumberofSegments0.000.020.040.06DensityGroundTruthGenerated024No.ofSegments(LogTransformed)0.00.10.20.30.40.5DensityGroundTruthGenerated−50050100150NumberofSegments0.000.010.020.030.04DensityGroundTruthGenerated−20246No.ofSegments(LogTransformed)0.00.10.20.30.4DensityGroundTruthGenerated050100NumberofSegments0.000.010.020.030.040.05DensityGroundTruthGenerated0246No.ofSegments(LogTransformed)0.00.10.20.30.4DensityGroundTruthGenerated−250255075100NumberofSegments0.000.010.020.030.04DensityGroundTruthGenerated0246No.ofSegments(LogTransformed)0.00.10.20.30.4DensityGroundTruthGenerated−250255075NumberofSegments0.000.020.040.06DensityGroundTruthGenerated024No.ofSegments(LogTransformed)0.00.10.20.30.40.5DensityGroundTruthGenerated−20020406080NumberofSegments0.000.010.020.030.04DensityGroundTruthGenerated024No.ofSegments(LogTransformed)0.00.20.40.6DensityGroundTruthGenerated\f(1)\n",
      "\n",
      "(4)\n",
      "\n",
      "(2)\n",
      "\n",
      "(5)\n",
      "\n",
      "(3)\n",
      "\n",
      "(6)\n",
      "\n",
      "Fig. 10. ECDF plots for number of downl downloaded segments, across different scenarios.\n",
      "\n",
      "29\n",
      "\n",
      "101No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.100101102No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.100101102No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.101No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.101No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.101No.ofSegments(LogScale)0.20.40.60.81.0Cuml.%ofSegmentsGroundTruthGeneratedMaxKSDist.\n"
     ]
    }
   ],
   "source": [
    "def responsing(text: str, max_results: int) -> list:\n",
    "    all_texts = []\n",
    "    url = \"http://localhost:5000/translate\"\n",
    "    data = {\n",
    "        \"q\": text,\n",
    "        \"source\": \"ru\",\n",
    "        \"target\": \"en\"\n",
    "    }\n",
    "    response = requests.post(url, json=data)\n",
    "    result = response.json()\n",
    "    text = result['translatedText']\n",
    "    print(text)\n",
    "    arxiv_results = search_arxiv(text, max_results=5)\n",
    "    print(\"arXiv results:\")\n",
    "    for res in arxiv_results:\n",
    "        all_texts.append(extract_text_from_pdf_url(res['pdf_url']))\n",
    "\n",
    "    return all_texts\n",
    "\n",
    "print(responsing('трансформеры', 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arXiv results:\n",
      "- Q-Insight: Understanding Image Quality via Visual Reinforcement Learning (2)\n",
      "- DSO: Aligning 3D Generators with Simulation Feedback for Physical\n",
      "  Soundness (2)\n",
      "- Self-Evolving Multi-Agent Simulations for Realistic Clinical\n",
      "  Interactions (2)\n",
      "- TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D\n",
      "  Gaussian Splatting (2)\n",
      "- Think Before Recommend: Unleashing the Latent Reasoning Power for\n",
      "  Sequential Recommendation (2)\n"
     ]
    }
   ],
   "source": [
    "arxiv_results = search_arxiv(\"transformers in NLP\", max_results=5)\n",
    "print(\"arXiv results:\")\n",
    "for res in arxiv_results:\n",
    "    print(f\"- {res['title']} ({res['published'][:1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/pdf/2503.22679v1\n"
     ]
    }
   ],
   "source": [
    "print(arxiv_results[0]['pdf_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "wikipedia.set_lang(\"en\")\n",
    "content = wikipedia.summary(\"Transformer (deep learning architecture)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Парсинг query='Transformers in machine learning' page=1\n",
      "INFO:httpx:HTTP Request: GET https://www.google.com/search?hl=en&q=Transformers%20in%20machine%20learning \"HTTP/2 200 OK\"\n",
      "INFO:__main__:Найдено 0 результатов на странице 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты поиска для 'Transformers in machine learning' (страница 1):\n",
      "   Нет результатов или страница заблокирована Google.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Парсинг query='Transformers in machine learning' page=2\n",
      "INFO:httpx:HTTP Request: GET https://www.google.com/search?hl=en&q=Transformers%20in%20machine%20learning&start=10 \"HTTP/2 200 OK\"\n",
      "INFO:__main__:Найдено 0 результатов на странице 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты поиска для 'Transformers in machine learning' (страница 2):\n",
      "   Нет результатов или страница заблокирована Google.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Парсинг query='Transformers in machine learning' page=3\n",
      "INFO:httpx:HTTP Request: GET https://www.google.com/search?hl=en&q=Transformers%20in%20machine%20learning&start=20 \"HTTP/2 200 OK\"\n",
      "INFO:__main__:Найдено 0 результатов на странице 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты поиска для 'Transformers in machine learning' (страница 3):\n",
      "   Нет результатов или страница заблокирована Google.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from urllib.parse import quote, urlparse, parse_qs\n",
    "from httpx import Client\n",
    "from parsel import Selector\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 1. Создаем HTTP клиент с заголовками, имитирующими браузер\n",
    "client = Client(\n",
    "    headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,ru;q=0.8\",\n",
    "    },\n",
    "    follow_redirects=True,\n",
    "    http2=True,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "def clean_url(url: str) -> str:\n",
    "    \"\"\"Очищает URL от трекинговых параметров и редиректов Google\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    \n",
    "    # Для Google-редиректов\n",
    "    if parsed.netloc.endswith(\"google.com\") and parsed.path == \"/url\":\n",
    "        return parse_qs(parsed.query).get(\"q\", [\"\"])[0]\n",
    "    \n",
    "    return url\n",
    "\n",
    "def parse_search_results(selector: Selector):\n",
    "    \"\"\"Парсит результаты поиска с Google страницы\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Используем актуальные селекторы для Google Search\n",
    "    for box in selector.xpath(\"//div[@id='search']//div[@class='tF2Cxc']\"):\n",
    "        # Извлечение заголовка\n",
    "        title_elem = box.xpath(\".//h3/text()\").get()\n",
    "        # Извлечение ссылки\n",
    "        link_elem = box.xpath(\".//a/@href\").get()\n",
    "        # Извлечение описания\n",
    "        snippet_elem = box.xpath(\".//div[@data-sncf]//text()\").getall()\n",
    "        \n",
    "        if not title_elem or not link_elem:\n",
    "            continue\n",
    "        \n",
    "        title = title_elem.strip()\n",
    "        url = clean_url(link_elem)\n",
    "        snippet = \" \".join([s.strip() for s in snippet_elem])[:200]  # Ограничиваем длину сниппета\n",
    "\n",
    "        if not url or \"google.com\" in url:\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"snippet\": snippet\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def scrape_search(query: str, page=1):\n",
    "    \"\"\"Парсит результаты поиска для заданного запроса\"\"\"\n",
    "    # Формируем URL\n",
    "    url = f\"https://www.google.com/search?hl=en&q={quote(query)}\"\n",
    "    if page > 1:\n",
    "        url += f\"&start={10 * (page - 1)}\"\n",
    "    \n",
    "    logger.info(f\"Парсинг {query=} {page=}\")\n",
    "    \n",
    "    try:\n",
    "        response = client.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Проверяем, не требует ли Google капчу\n",
    "        selector = Selector(response.text)\n",
    "        \n",
    "        # Проверка на наличие капчи\n",
    "        if selector.xpath(\"//div[contains(text(), 'Our systems have detected unusual traffic')]\").get():\n",
    "            logger.warning(\"Обнаружена капча от Google. Попробуйте позже или используйте Google Programmable Search Engine\")\n",
    "            return {\"query\": query, \"page\": page, \"results\": []}\n",
    "        \n",
    "        # Парсим результаты\n",
    "        search_results = parse_search_results(selector)\n",
    "        logger.info(f\"Найдено {len(search_results)} результатов на странице {page}\")\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"page\": page,\n",
    "            \"results\": search_results\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка при парсинге {query} (страница {page}): {e}\")\n",
    "        return {\"query\": query, \"page\": page, \"results\": []}\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Transformers in machine learning\"\n",
    "    for page in [1, 2, 3]:\n",
    "        try:\n",
    "            results = scrape_search(query, page=page)\n",
    "            \n",
    "            print(f\"\\nРезультаты поиска для '{query}' (страница {page}):\")\n",
    "            if results[\"results\"]:\n",
    "                for i, result in enumerate(results[\"results\"], 1):\n",
    "                    print(f\"{i}. {result['title']}\")\n",
    "                    print(f\"   {result['url']}\")\n",
    "                    print(f\"   {result['snippet']}\\n\")\n",
    "            else:\n",
    "                print(\"   Нет результатов или страница заблокирована Google.\\n\")\n",
    "            \n",
    "            time.sleep(3)  # Добавляем паузу между страницами\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при обработке страницы {page}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ethd\\conda\\envs\\neuro-research-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\ethd\\conda\\envs\\neuro-research-env\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: 36867 символов\n",
      "После очистки: 36705 символов\n",
      "Перевод части 1/37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ethd\\conda\\envs\\neuro-research-env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4106: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перевод части 2/37\n",
      "Перевод части 3/37\n",
      "Перевод части 4/37\n",
      "Перевод части 5/37\n",
      "Перевод части 6/37\n",
      "Перевод части 7/37\n",
      "Перевод части 8/37\n",
      "Перевод части 9/37\n",
      "Перевод части 10/37\n",
      "Перевод части 11/37\n",
      "Перевод части 12/37\n",
      "Перевод части 13/37\n",
      "Перевод части 14/37\n",
      "Перевод части 15/37\n",
      "Перевод части 16/37\n",
      "Перевод части 17/37\n",
      "Перевод части 18/37\n",
      "Перевод части 19/37\n",
      "Перевод части 20/37\n",
      "Перевод части 21/37\n",
      "Перевод части 22/37\n",
      "Перевод части 23/37\n",
      "Перевод части 24/37\n",
      "Перевод части 25/37\n",
      "Перевод части 26/37\n",
      "Перевод части 27/37\n",
      "Перевод части 28/37\n",
      "Перевод части 29/37\n",
      "Перевод части 30/37\n",
      "Перевод части 31/37\n",
      "Перевод части 32/37\n",
      "Перевод части 33/37\n",
      "Перевод части 34/37\n",
      "Перевод части 35/37\n",
      "Перевод части 36/37\n",
      "Перевод части 37/37\n",
      "После перевода: 25928 символов\n",
      "Перевод завершён.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "import re\n",
    "\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-ru-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def translate(text: str) -> str:\n",
    "    \"\"\"Переводит текст с русского на английский\"\"\"\n",
    "    tokenized_text = tokenizer.prepare_seq2seq_batch([text], return_tensors='pt').to(device)\n",
    "    translated = model.generate(**tokenized_text)\n",
    "    result = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "def translate_file(file_path: str):\n",
    "    \"\"\"Читает файл, переводит текст и сохраняет результат обратно\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            input_text = file.read()\n",
    "\n",
    "        print(\"Файл успешно прочитан.\")\n",
    "\n",
    "        translated_text = translate(input_text)\n",
    "\n",
    "        print(\"Перевод завершён.\")\n",
    "\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(translated_text)\n",
    "\n",
    "        print(f\"Перевод сохранён в файл: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка: {e}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    # Удаление HTML-тегов\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    \n",
    "    # Удаление URL\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    \n",
    "    # Удаление повторяющихся строк\n",
    "    lines = text.split(\"\\n\")\n",
    "    seen = set()\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and line not in seen:\n",
    "            seen.add(line)\n",
    "            cleaned_lines.append(line)\n",
    "    text = \"\\n\".join(cleaned_lines)\n",
    "    \n",
    "    # Удаление технических строк\n",
    "    text = re.sub(r\"(?i)(?:etext|from|q)=\\S+\", \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def translate_file_in_parts(file_path: str):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        input_text = file.read()\n",
    "    \n",
    "    print(f\"Исходный текст: {len(input_text)} символов\")\n",
    "    \n",
    "    cleaned_text = clean_text(input_text)\n",
    "    print(f\"После очистки: {len(cleaned_text)} символов\")\n",
    "    \n",
    "    translated_text = translate_in_chunks(cleaned_text)\n",
    "    print(f\"После перевода: {len(translated_text)} символов\")\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(translated_text)\n",
    "    \n",
    "    print(\"Перевод завершён.\")\n",
    "\n",
    "def translate_in_chunks(text, chunk_size=1000):\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    translated = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Перевод части {i+1}/{len(chunks)}\")\n",
    "        try:\n",
    "            result = translate(chunk)\n",
    "            if result:\n",
    "                translated.append(result)\n",
    "            else:\n",
    "                print(f\"Часть {i+1} не переведена\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при переводе части {i+1}: {e}\")\n",
    "\n",
    "    return \"\\n\".join(translated)\n",
    "\n",
    "\n",
    "file_path = r\"D:\\ethd\\печать\\fceb0dad-0cf7-40b7-9c86-2da0ea118b91_page.txt\"\n",
    "translate_file_in_parts(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro-research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
