# Research Pipeline: Многоагентная система для анализа и верификации информации

---

## Описание проекта

Данный проект представляет собой автоматизированную платформу (research pipeline), предназначенную для поиска, проверки, анализа и визуализации информации из различных источников (новостные сайты, соцсети, API). Система построена на многоагентной архитектуре, в которой различные агенты выполняют специализированные задачи, взаимодействуя между собой для получения точных и достоверных результатов.

---

## Архитектура проекта

Проект основан на многоагентной архитектуре и включает следующие компоненты:

### 1. Поисковые агенты (`Search Agents`)
- Сбор данных с новостных сайтов, социальных сетей и API.
- Парсинг данных с использованием NLP-инструментов.

### 2. Агенты валидации (`Validation Agents`)
- Проверка достоверности информации (факт-чекинг, анализ репутации источников).
- Использование моделей машинного обучения (BERT, RoBERTa и иные).

### 3. Агенты аналитики (`Analytics Agents`)
- Тематическое моделирование и кластеризация новостей.
- Извлечение ключевых сущностей и связей между ними.

### 3. Координатор (`Orchestrator`)
- Управление задачами и интеграция результатов.
- Микросервисная архитектура и управление очередями задач.

---

## Технологический стек

- **Сбор данных**: `Scrapy`, `BeautifulSoup`, `Selenium`, `NewsAPI`, Twitter API, Google News API.
- **Верификация данных**: Hugging Face (`BERT`, `RoBERTa`), FactCheck API.
- **Аналитика**: BERTopic, spaCy, Neo4j, Apache Spark.
- **Визуализация**: Dash, Matplotlib, Tableau, PowerBI
- **Инфраструктура**: Docker, Kubernetes, Apache Kafka, RabbitMQ.
- **Хранение данных**: MongoDB, PostgreSQL, Neo4j.


